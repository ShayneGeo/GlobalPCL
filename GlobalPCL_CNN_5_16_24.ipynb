{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aebe848-8772-46a8-bde7-87d795a3718d",
   "metadata": {},
   "source": [
    "# THE FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09d4203-49b9-46b0-bf1c-52b35365022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "THEFOLDER = \"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GlobalPCL23\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458147b-a3b4-4898-a21b-dd7ac2e8f9a4",
   "metadata": {},
   "source": [
    "# Tile western Conus PCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7a94a2-6600-4a87-8ed0-684af2475414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "\n",
    "in_path = \"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\PCLCONUS\\\\Input\\\\PCL\\\\\"\n",
    "input_filename = 'pcl_west_wgs.tif'\n",
    "\n",
    "out_path = f\"{THEFOLDER}\\\\PCLTILES\\\\\"\n",
    "output_filename = 'pcltile_{}-{}.tif'\n",
    "\n",
    "widthtile = 5000\n",
    "heighttile = 5000\n",
    "\n",
    "def get_tiles(ds, width=widthtile, height=heighttile):\n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in offsets:\n",
    "        window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "tile_numbers = []\n",
    "\n",
    "with rio.open(os.path.join(in_path, input_filename)) as inds:\n",
    "    tile_width, tile_height = widthtile, heighttile\n",
    "    nodata = inds.nodata\n",
    "    meta = inds.meta.copy()\n",
    "    for window, transform in get_tiles(inds):\n",
    "        data = inds.read(window=window)\n",
    "        if nodata is not None and not (data == nodata).all():\n",
    "            meta['transform'] = transform\n",
    "            meta['width'], meta['height'] = window.width, window.height\n",
    "            tile_number = f\"{int(window.col_off)}-{int(window.row_off)}\"\n",
    "            tile_numbers.append(tile_number)\n",
    "            outpath = os.path.join(out_path, output_filename.format(int(window.col_off), int(window.row_off)))\n",
    "            with rio.open(outpath, 'w', **meta) as outds:\n",
    "                outds.write(data)\n",
    "\n",
    "# Print or store the tile numbers\n",
    "TILENUMBER = tile_numbers\n",
    "\n",
    "del in_path, input_filename, tile_numbers\n",
    "del out_path, output_filename, widthtile, heighttile, tile_width, tile_height\n",
    "del meta, nodata, window, inds, get_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf52f5-cd75-4d08-ad7b-6af9fc4e84dc",
   "metadata": {},
   "source": [
    "# Downlaod training data and create training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1ec9ea-c8f0-45a7-bbdf-cf5c61cb4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import subprocess\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from osgeo import gdal\n",
    "# import rioxarray\n",
    "# import planetary_computer\n",
    "# from pystac_client import Client\n",
    "# import osmnx as ox\n",
    "# import rasterio\n",
    "# from rasterio.features import rasterize\n",
    "# from rasterio.windows import from_bounds, Window\n",
    "# import numpy as np\n",
    "# import scipy.ndimage\n",
    "# from shapely.geometry import box, Point\n",
    "# from geopandas import GeoDataFrame\n",
    "# import matplotlib.pyplot as plt\n",
    "# from rasterio.plot import show\n",
    "# import json\n",
    "\n",
    "# TILENUMBER = ['75000-35000', '75000-40000', '75000-45000']\n",
    "# CHIP_SIZE = 128\n",
    "# CHECKPOINT_FILE = r\"C:\\Users\\smdur\\OneDrive\\Desktop\\PCLTraining3\\checkpoint.json\"\n",
    "\n",
    "# def load_checkpoint():\n",
    "#     if os.path.exists(CHECKPOINT_FILE):\n",
    "#         with open(CHECKPOINT_FILE, 'r') as f:\n",
    "#             return json.load(f)\n",
    "#     return {}\n",
    "\n",
    "# def save_checkpoint(tile_number, step, data=None):\n",
    "#     checkpoint = load_checkpoint()\n",
    "#     if tile_number not in checkpoint:\n",
    "#         checkpoint[tile_number] = {}\n",
    "#     checkpoint[tile_number]['step'] = step\n",
    "#     if data:\n",
    "#         checkpoint[tile_number].update(data)\n",
    "#     with open(CHECKPOINT_FILE, 'w') as f:\n",
    "#         json.dump(checkpoint, f)\n",
    "\n",
    "# def delete_non_resampled_files(resampled_files, tif_dir):\n",
    "#     for file in os.listdir(tif_dir):\n",
    "#         if file not in resampled_files and file.endswith('.tif'):\n",
    "#             file_path = os.path.join(tif_dir, file)\n",
    "#             try:\n",
    "#                 os.remove(file_path)\n",
    "#                 print(f\"Deleted: {file_path}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "# def process_dem(tif_path, tif_dir, tile_number):\n",
    "#     tif_data = rioxarray.open_rasterio(tif_path)\n",
    "#     bbox_of_interest = tif_data.rio.bounds()\n",
    "#     catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "#     search = catalog.search(collections=[\"cop-dem-glo-30\"], bbox=bbox_of_interest)\n",
    "#     items = list(search.get_items())\n",
    "    \n",
    "#     def process_item(item, idx):\n",
    "#         signed_asset = planetary_computer.sign(item.assets[\"data\"])\n",
    "#         data = rioxarray.open_rasterio(signed_asset.href).squeeze().drop(\"band\")\n",
    "#         data.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "#         output_tif_path = os.path.join(tif_dir, f\"output_dataDEM_{idx}.tif\")\n",
    "#         data.rio.to_raster(output_tif_path)\n",
    "    \n",
    "#     with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "#         for i, item in enumerate(items):\n",
    "#             executor.submit(process_item, item, i)\n",
    "\n",
    "#     output_tif = os.path.join(tif_dir, f\"outputtile_DEM_{tile_number}.tif\")\n",
    "#     merge_command = [\n",
    "#         \"python\", \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "#         \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "#         \"-o\", output_tif,\n",
    "#         \"-n\", \"-9999\", \"-a_nodata\", \"-9999\"] + glob.glob(os.path.join(tif_dir, \"output_dataDEM_*.tif\"))\n",
    "\n",
    "#     process_hag = subprocess.run(merge_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "#     if process_hag.returncode != 0:\n",
    "#         print(f\"Error in merging DEM: {process_hag.stderr}\")\n",
    "#         return None\n",
    "\n",
    "#     src_ds = gdal.Open(output_tif, gdal.GA_ReadOnly)\n",
    "#     target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "#     driver = gdal.GetDriverByName('GTiff')\n",
    "#     output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataDEM_{tile_number}.tif\")\n",
    "#     out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "#     out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "#     out_ds.SetProjection(target_ds.GetProjection())\n",
    "#     gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "#     src_ds, target_ds, out_ds = None, None, None\n",
    "\n",
    "#     os.remove(output_tif)\n",
    "#     for tif in glob.glob(os.path.join(tif_dir, \"output_dataDEM_*.tif\")):\n",
    "#         try:\n",
    "#             os.remove(tif)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to delete {tif}: {e}\")\n",
    "\n",
    "#     return output_resampled_path\n",
    "\n",
    "#     del tif_data, bbox_of_interest, catalog, search, items\n",
    "#     del output_tif, merge_command, process_hag\n",
    "#     del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "# def process_lidar(tif_path, tif_dir, tile_number):\n",
    "#     lidar_dir = r\"C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalData\\LIDAR2\"\n",
    "#     lidar_tifs = glob.glob(os.path.join(lidar_dir, \"*.tif\"))\n",
    "\n",
    "#     # Get the bounding box of the input tif_path\n",
    "#     with rasterio.open(tif_path) as src:\n",
    "#         bbox = src.bounds\n",
    "#         input_geom = box(bbox.left, bbox.bottom, bbox.right, bbox.top)\n",
    "\n",
    "#     # Find overlapping LIDAR tiles\n",
    "#     overlapping_tifs = []\n",
    "#     for tif in lidar_tifs:\n",
    "#         with rasterio.open(tif) as src:\n",
    "#             lidar_bbox = src.bounds\n",
    "#             lidar_geom = box(lidar_bbox.left, lidar_bbox.bottom, lidar_bbox.right, lidar_bbox.top)\n",
    "#             if input_geom.intersects(lidar_geom):\n",
    "#                 overlapping_tifs.append(tif)\n",
    "\n",
    "#     if not overlapping_tifs:\n",
    "#         print(f\"No overlapping LIDAR tiles found for {tile_number}\")\n",
    "#         return None\n",
    "\n",
    "#     output_tif = os.path.join(tif_dir, f\"outputtile_lidar_{tile_number}.tif\")\n",
    "#     merge_command = [\n",
    "#         \"python\", \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "#         \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "#         \"-o\", output_tif,\n",
    "#         \"-n\", \"255\", \"-a_nodata\", \"255\"] + overlapping_tifs\n",
    "\n",
    "#     process_hag = subprocess.run(merge_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "#     if process_hag.returncode != 0:\n",
    "#         print(f\"Error in merging LIDAR: {process_hag.stderr}\")\n",
    "#         return None\n",
    "\n",
    "#     src_ds = gdal.Open(output_tif, gdal.GA_ReadOnly)\n",
    "#     target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "#     driver = gdal.GetDriverByName('GTiff')\n",
    "#     output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataLIDAR_{tile_number}.tif\")\n",
    "#     out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "#     out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "#     out_ds.SetProjection(target_ds.GetProjection())\n",
    "#     gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "#     src_ds, target_ds, out_ds = None, None, None\n",
    "\n",
    "#     os.remove(output_tif)\n",
    "#     return output_resampled_path\n",
    "\n",
    "#     del lidar_tifs, bbox, input_geom, overlapping_tifs, lidar_bbox, lidar_geom\n",
    "#     del output_tif, merge_command, process_hag\n",
    "#     del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "# def process_rivers(tif_path, tif_dir, tile_number):\n",
    "#     dem_data = rioxarray.open_rasterio(tif_path)\n",
    "#     bbox = dem_data.rio.bounds()\n",
    "#     custom_filter = '[\"waterway\"~\"river\"]'\n",
    "#     graph = ox.graph_from_bbox(bbox[3], bbox[1], bbox[2], bbox[0], custom_filter=custom_filter, simplify=True, retain_all=True, truncate_by_edge=True)\n",
    "#     gdf = ox.graph_to_gdfs(graph, nodes=False)\n",
    "\n",
    "#     with rasterio.open(tif_path) as src:\n",
    "#         window = from_bounds(*src.bounds, src.transform)\n",
    "#         transform = rasterio.windows.transform(window, src.transform)\n",
    "#         raster = np.zeros((int(window.height), int(window.width)), dtype=np.uint8)\n",
    "#         shapes = ((geom, 1) for geom in gdf['geometry'])\n",
    "#         burned = rasterize(shapes, out=raster, fill=0, transform=transform, all_touched=True)\n",
    "#         distance_grid = scipy.ndimage.distance_transform_edt(burned == 0)\n",
    "#         decay_grid = np.exp(-0.07 * distance_grid)\n",
    "\n",
    "#         clipped_meta = src.meta.copy()\n",
    "#         clipped_meta.update({\"driver\": \"GTiff\", \"height\": int(window.height), \"width\": int(window.width), \"transform\": transform, \"dtype\": rasterio.float32, \"count\": 1, \"compress\": 'lzw'})\n",
    "#         output_path = os.path.join(tif_dir, f'exponential_decay_CO_river_{tile_number}.tif')\n",
    "#         with rasterio.open(output_path, 'w', **clipped_meta) as dst:\n",
    "#             dst.write(decay_grid.astype(np.float32), 1)\n",
    "\n",
    "#     src_ds = gdal.Open(output_path, gdal.GA_ReadOnly)\n",
    "#     target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "#     driver = gdal.GetDriverByName('GTiff')\n",
    "#     output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataRivers_{tile_number}.tif\")\n",
    "#     out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "#     out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "#     out_ds.SetProjection(target_ds.GetProjection())\n",
    "#     gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "#     src_ds, target_ds, out_ds = None, None, None\n",
    "#     os.remove(output_path)\n",
    "\n",
    "#     return output_resampled_path\n",
    "\n",
    "#     del dem_data, bbox, custom_filter, graph, gdf\n",
    "#     del window, transform, raster, shapes, burned, distance_grid, decay_grid\n",
    "#     del clipped_meta, output_path\n",
    "#     del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "# def process_roads(tif_path, tif_dir, tile_number):\n",
    "#     extent_data = rioxarray.open_rasterio(tif_path)\n",
    "#     bbox = extent_data.rio.bounds()\n",
    "#     graph = ox.graph_from_bbox(bbox[3], bbox[1], bbox[2], bbox[0], network_type='drive', simplify=True)\n",
    "#     gdf = ox.graph_to_gdfs(graph, nodes=False)\n",
    "\n",
    "#     with rasterio.open(tif_path) as src:\n",
    "#         window = from_bounds(*src.bounds, src.transform)\n",
    "#         transform = rasterio.windows.transform(window, src.transform)\n",
    "#         raster = np.zeros((int(window.height), int(window.width)), dtype=np.uint8)\n",
    "#         shapes = ((geom, 1) for geom in gdf['geometry'])\n",
    "#         burned = rasterize(shapes, out=raster, fill=0, transform=transform, all_touched=True)\n",
    "#         distance_grid = scipy.ndimage.distance_transform_edt(burned == 0)\n",
    "#         decay_grid = np.exp(-0.07 * distance_grid)\n",
    "\n",
    "#         clipped_meta = src.meta.copy()\n",
    "#         clipped_meta.update({\"driver\": \"GTiff\", \"height\": int(window.height), \"width\": int(window.width), \"transform\": transform, \"dtype\": rasterio.float32, \"count\": 1, \"compress\": 'lzw'})\n",
    "#         output_path = os.path.join(tif_dir, f'exponential_decay_CO_roads_{tile_number}.tif')\n",
    "#         with rasterio.open(output_path, 'w', **clipped_meta) as dst:\n",
    "#             dst.write(decay_grid.astype(np.float32), 1)\n",
    "\n",
    "#     src_ds = gdal.Open(output_path, gdal.GA_ReadOnly)\n",
    "#     target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "#     driver = gdal.GetDriverByName('GTiff')\n",
    "#     output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataRoads_{tile_number}.tif\")\n",
    "#     out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "#     out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "#     out_ds.SetProjection(target_ds.GetProjection())\n",
    "#     gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "#     src_ds, target_ds, out_ds = None, None, None\n",
    "#     os.remove(output_path)\n",
    "\n",
    "#     return output_resampled_path\n",
    "\n",
    "#     del extent_data, bbox, graph, gdf\n",
    "#     del window, transform, raster, shapes, burned, distance_grid, decay_grid\n",
    "#     del clipped_meta, output_path\n",
    "#     del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "# def generate_random_points(geometry, num_points):\n",
    "#     points = []\n",
    "#     min_x, min_y, max_x, max_y = geometry.bounds\n",
    "#     while len(points) < num_points:\n",
    "#         random_point = Point(np.random.uniform(min_x, max_x), np.random.uniform(min_y, max_y))\n",
    "#         if random_point.within(geometry):\n",
    "#             points.append(random_point)\n",
    "#     return points\n",
    "\n",
    "\n",
    "# def process_chips(tif_path, tif_dir, lat_long, chip_size=128):\n",
    "#     resampled_lidar_path = os.path.join(tif_dir, f\"output_resampled_dataLIDAR_{tile_number}.tif\")\n",
    "#     resampled_dem_path = os.path.join(tif_dir, f\"output_resampled_dataDEM_{tile_number}.tif\")\n",
    "#     resampled_rivers_path = os.path.join(tif_dir, f\"output_resampled_dataRivers_{tile_number}.tif\")\n",
    "#     resampled_roads_path = os.path.join(tif_dir, f\"output_resampled_dataRoads_{tile_number}.tif\")\n",
    "\n",
    "#     training_chips_dir = os.path.join(THEFOLDER, \"trainingchips\")\n",
    "#     os.makedirs(training_chips_dir, exist_ok=True)\n",
    "\n",
    "#     for i, (lat, lon) in enumerate(lat_long):\n",
    "#         try:\n",
    "#             paths = [resampled_lidar_path, resampled_dem_path, resampled_rivers_path, resampled_roads_path, tif_path]\n",
    "#             labels = ['lidar', 'dem', 'rivers', 'roads', 'pcllabels']\n",
    "            \n",
    "#             for path, label in zip(paths, labels):\n",
    "#                 with rasterio.open(path) as src:\n",
    "#                     col, row = src.index(lon, lat)\n",
    "#                     window = Window(col - chip_size // 2, row - chip_size // 2, chip_size, chip_size)\n",
    "#                     chip_data = src.read(1, window=window)\n",
    "                    \n",
    "#                     out_meta = src.meta.copy()\n",
    "#                     out_meta.update({\n",
    "#                         \"driver\": \"GTiff\",\n",
    "#                         \"height\": chip_size,\n",
    "#                         \"width\": chip_size,\n",
    "#                         \"transform\": src.window_transform(window)\n",
    "#                     })\n",
    "\n",
    "#                     chip_output_dir = os.path.join(training_chips_dir, label)\n",
    "#                     os.makedirs(chip_output_dir, exist_ok=True)\n",
    "                    \n",
    "#                     chip_output_path = os.path.join(chip_output_dir, f\"{label.upper()}_Chip_{tile_number}_{i}.tif\")\n",
    "\n",
    "#                     if chip_data.shape == (chip_size, chip_size) and np.any(chip_data != src.nodata):\n",
    "#                         with rasterio.open(chip_output_path, \"w\", **out_meta) as dest:\n",
    "#                             dest.write(chip_data, 1)\n",
    "#                     else:\n",
    "#                         print(f\"Skipping {label} chip {i} because it is not properly shaped or is filled with nodata.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred while processing chip {i}: {e}\")\n",
    "            \n",
    "#     del resampled_lidar_path, resampled_dem_path, resampled_rivers_path, resampled_roads_path\n",
    "#     del training_chips_dir, paths, labels, col, row, window, chip_data, out_meta, chip_output_dir, chip_output_path\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     checkpoint = load_checkpoint()\n",
    "#     for tile_number in TILENUMBER:\n",
    "#         tif_path = f\"{THEFOLDER}\\\\PCLTILES\\\\pcltile_{tile_number}.tif\"\n",
    "#         tif_dir = f\"{THEFOLDER}\\\\TIFFOUTPUT\\\\{tile_number}\"\n",
    "#         os.makedirs(tif_dir, exist_ok=True)\n",
    "\n",
    "#         if tile_number not in checkpoint or checkpoint[tile_number]['step'] < 1:\n",
    "#             resampled_dem_path = process_dem(tif_path, tif_dir, tile_number)\n",
    "#             save_checkpoint(tile_number, 1, {'resampled_dem_path': resampled_dem_path})\n",
    "\n",
    "#         if tile_number not in checkpoint or checkpoint[tile_number]['step'] < 2:\n",
    "#             resampled_lidar_path = process_lidar(tif_path, tif_dir, tile_number)\n",
    "#             save_checkpoint(tile_number, 2, {'resampled_lidar_path': resampled_lidar_path})\n",
    "\n",
    "#         if tile_number not in checkpoint or checkpoint[tile_number]['step'] < 3:\n",
    "#             resampled_rivers_path = process_rivers(tif_path, tif_dir, tile_number)\n",
    "#             save_checkpoint(tile_number, 3, {'resampled_rivers_path': resampled_rivers_path})\n",
    "\n",
    "#         if tile_number not in checkpoint or checkpoint[tile_number]['step'] < 4:\n",
    "#             resampled_roads_path = process_roads(tif_path, tif_dir, tile_number)\n",
    "#             save_checkpoint(tile_number, 4, {'resampled_roads_path': resampled_roads_path})\n",
    "\n",
    "#         resampled_files = [\n",
    "#             checkpoint[tile_number]['resampled_dem_path'],\n",
    "#             checkpoint[tile_number]['resampled_lidar_path'],\n",
    "#             checkpoint[tile_number]['resampled_rivers_path'],\n",
    "#             checkpoint[tile_number]['resampled_roads_path']\n",
    "#         ]\n",
    "\n",
    "#         delete_non_resampled_files([os.path.basename(f) for f in resampled_files], tif_dir)\n",
    "\n",
    "#         if tile_number not in checkpoint or checkpoint[tile_number]['step'] < 5:\n",
    "#             # Generate random points within the tile bounds\n",
    "#             with rasterio.open(tif_path) as src:\n",
    "#                 bounds = src.bounds\n",
    "#                 crs = src.crs\n",
    "#                 img = src.read(1)\n",
    "\n",
    "#             rect = box(bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "#             buffered_rect = rect.buffer(-0.15)\n",
    "#             random_points = generate_random_points(buffered_rect, 5000)\n",
    "#             gdf_points = GeoDataFrame(geometry=random_points, crs=crs).to_crs(crs)\n",
    "#             gdf_points_wgs84 = gdf_points.to_crs(epsg=4326)\n",
    "#             lat_long = gdf_points_wgs84.geometry.apply(lambda geom: (geom.y, geom.x)).tolist()\n",
    "\n",
    "#             save_checkpoint(tile_number, 5, {'lat_long': lat_long})\n",
    "\n",
    "#         if tile_number in checkpoint and 'lat_long' in checkpoint[tile_number]:\n",
    "#             lat_long = checkpoint[tile_number]['lat_long']\n",
    "#         else:\n",
    "#             with rasterio.open(tif_path) as src:\n",
    "#                 bounds = src.bounds\n",
    "#                 crs = src.crs\n",
    "#                 img = src.read(1)\n",
    "\n",
    "#             rect = box(bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "#             buffered_rect = rect.buffer(-0.15)\n",
    "#             random_points = generate_random_points(buffered_rect, 5000)\n",
    "#             gdf_points = GeoDataFrame(geometry=random_points, crs=crs).to_crs(crs)\n",
    "#             gdf_points_wgs84 = gdf_points.to_crs(epsg=4326)\n",
    "#             lat_long = gdf_points_wgs84.geometry.apply(lambda geom: (geom.y, geom.x)).tolist()\n",
    "#             save_checkpoint(tile_number, 5, {'lat_long': lat_long})\n",
    "\n",
    "#         if tile_number not in checkpoint or checkpoint[tile_number]['step'] < 6:\n",
    "#             process_chips(tif_path, tif_dir, lat_long)\n",
    "#             save_checkpoint(tile_number, 6)\n",
    "\n",
    "#         print(f\"Processing for tile {tile_number} completed.\")\n",
    "\n",
    "#     print(\"All processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5035ed5d-91bc-497d-a6db-b3ad14e76d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smdur\\anaconda3\\envs\\globalpcl\\lib\\site-packages\\pystac_client\\item_search.py:834: FutureWarning: get_items() is deprecated, use items() instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for tile 75000-35000 completed.\n",
      "Processing for tile 75000-40000 completed.\n",
      "Processing for tile 75000-45000 completed.\n",
      "All processing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from osgeo import gdal\n",
    "import rioxarray\n",
    "import planetary_computer\n",
    "from pystac_client import Client\n",
    "import osmnx as ox\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.windows import from_bounds, Window\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from shapely.geometry import box, Point\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "\n",
    "TILENUMBER = ['75000-35000', '75000-40000', '75000-45000']\n",
    "CHIP_SIZE = 128\n",
    "\n",
    "def delete_non_resampled_files(resampled_files, tif_dir):\n",
    "    for file in os.listdir(tif_dir):\n",
    "        if file not in resampled_files and file.endswith('.tif'):\n",
    "            file_path = os.path.join(tif_dir, file)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "def process_dem(tif_path, tif_dir, tile_number):\n",
    "    tif_data = rioxarray.open_rasterio(tif_path)\n",
    "    bbox_of_interest = tif_data.rio.bounds()\n",
    "    catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "    search = catalog.search(collections=[\"cop-dem-glo-30\"], bbox=bbox_of_interest)\n",
    "    items = list(search.get_items())\n",
    "    \n",
    "    def process_item(item, idx):\n",
    "        signed_asset = planetary_computer.sign(item.assets[\"data\"])\n",
    "        data = rioxarray.open_rasterio(signed_asset.href).squeeze().drop(\"band\")\n",
    "        data.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "        output_tif_path = os.path.join(tif_dir, f\"output_dataDEM_{idx}.tif\")\n",
    "        data.rio.to_raster(output_tif_path)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        for i, item in enumerate(items):\n",
    "            executor.submit(process_item, item, i)\n",
    "\n",
    "    output_tif = os.path.join(tif_dir, f\"outputtile_DEM_{tile_number}.tif\")\n",
    "    merge_command = [\n",
    "        \"python\", \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "        \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "        \"-o\", output_tif,\n",
    "        \"-n\", \"-9999\", \"-a_nodata\", \"-9999\"] + glob.glob(os.path.join(tif_dir, \"output_dataDEM_*.tif\"))\n",
    "\n",
    "    process_hag = subprocess.run(merge_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if process_hag.returncode != 0:\n",
    "        print(f\"Error in merging DEM: {process_hag.stderr}\")\n",
    "        return None\n",
    "\n",
    "    src_ds = gdal.Open(output_tif, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataDEM_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "\n",
    "    os.remove(output_tif)\n",
    "    for tif in glob.glob(os.path.join(tif_dir, \"output_dataDEM_*.tif\")):\n",
    "        try:\n",
    "            os.remove(tif)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {tif}: {e}\")\n",
    "\n",
    "    return output_resampled_path\n",
    "\n",
    "    del tif_data, bbox_of_interest, catalog, search, items\n",
    "    del output_tif, merge_command, process_hag\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "def process_lidar(tif_path, tif_dir, tile_number):\n",
    "    lidar_dir = r\"C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalData\\LIDAR2\"\n",
    "    lidar_tifs = glob.glob(os.path.join(lidar_dir, \"*.tif\"))\n",
    "\n",
    "    # Get the bounding box of the input tif_path\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        bbox = src.bounds\n",
    "        input_geom = box(bbox.left, bbox.bottom, bbox.right, bbox.top)\n",
    "\n",
    "    # Find overlapping LIDAR tiles\n",
    "    overlapping_tifs = []\n",
    "    for tif in lidar_tifs:\n",
    "        with rasterio.open(tif) as src:\n",
    "            lidar_bbox = src.bounds\n",
    "            lidar_geom = box(lidar_bbox.left, lidar_bbox.bottom, lidar_bbox.right, lidar_bbox.top)\n",
    "            if input_geom.intersects(lidar_geom):\n",
    "                overlapping_tifs.append(tif)\n",
    "\n",
    "    if not overlapping_tifs:\n",
    "        print(f\"No overlapping LIDAR tiles found for {tile_number}\")\n",
    "        return None\n",
    "\n",
    "    output_tif = os.path.join(tif_dir, f\"outputtile_lidar_{tile_number}.tif\")\n",
    "    merge_command = [\n",
    "        \"python\", \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "        \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "        \"-o\", output_tif,\n",
    "        \"-n\", \"255\", \"-a_nodata\", \"255\"] + overlapping_tifs\n",
    "\n",
    "    process_hag = subprocess.run(merge_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if process_hag.returncode != 0:\n",
    "        print(f\"Error in merging LIDAR: {process_hag.stderr}\")\n",
    "        return None\n",
    "\n",
    "    src_ds = gdal.Open(output_tif, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataLIDAR_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "\n",
    "    os.remove(output_tif)\n",
    "    return output_resampled_path\n",
    "\n",
    "    del lidar_tifs, bbox, input_geom, overlapping_tifs, lidar_bbox, lidar_geom\n",
    "    del output_tif, merge_command, process_hag\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "def process_rivers(tif_path, tif_dir, tile_number):\n",
    "    dem_data = rioxarray.open_rasterio(tif_path)\n",
    "    bbox = dem_data.rio.bounds()\n",
    "    custom_filter = '[\"waterway\"~\"river\"]'\n",
    "    graph = ox.graph_from_bbox(bbox[3], bbox[1], bbox[2], bbox[0], custom_filter=custom_filter, simplify=True, retain_all=True, truncate_by_edge=True)\n",
    "    gdf = ox.graph_to_gdfs(graph, nodes=False)\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        window = from_bounds(*src.bounds, src.transform)\n",
    "        transform = rasterio.windows.transform(window, src.transform)\n",
    "        raster = np.zeros((int(window.height), int(window.width)), dtype=np.uint8)\n",
    "        shapes = ((geom, 1) for geom in gdf['geometry'])\n",
    "        burned = rasterize(shapes, out=raster, fill=0, transform=transform, all_touched=True)\n",
    "        distance_grid = scipy.ndimage.distance_transform_edt(burned == 0)\n",
    "        decay_grid = np.exp(-0.07 * distance_grid)\n",
    "\n",
    "        clipped_meta = src.meta.copy()\n",
    "        clipped_meta.update({\"driver\": \"GTiff\", \"height\": int(window.height), \"width\": int(window.width), \"transform\": transform, \"dtype\": rasterio.float32, \"count\": 1, \"compress\": 'lzw'})\n",
    "        output_path = os.path.join(tif_dir, f'exponential_decay_CO_river_{tile_number}.tif')\n",
    "        with rasterio.open(output_path, 'w', **clipped_meta) as dst:\n",
    "            dst.write(decay_grid.astype(np.float32), 1)\n",
    "\n",
    "    src_ds = gdal.Open(output_path, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataRivers_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "    os.remove(output_path)\n",
    "\n",
    "    return output_resampled_path\n",
    "\n",
    "    del dem_data, bbox, custom_filter, graph, gdf\n",
    "    del window, transform, raster, shapes, burned, distance_grid, decay_grid\n",
    "    del clipped_meta, output_path\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "def process_roads(tif_path, tif_dir, tile_number):\n",
    "    extent_data = rioxarray.open_rasterio(tif_path)\n",
    "    bbox = extent_data.rio.bounds()\n",
    "    graph = ox.graph_from_bbox(bbox[3], bbox[1], bbox[2], bbox[0], network_type='drive', simplify=True)\n",
    "    gdf = ox.graph_to_gdfs(graph, nodes=False)\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        window = from_bounds(*src.bounds, src.transform)\n",
    "        transform = rasterio.windows.transform(window, src.transform)\n",
    "        raster = np.zeros((int(window.height), int(window.width)), dtype=np.uint8)\n",
    "        shapes = ((geom, 1) for geom in gdf['geometry'])\n",
    "        burned = rasterize(shapes, out=raster, fill=0, transform=transform, all_touched=True)\n",
    "        distance_grid = scipy.ndimage.distance_transform_edt(burned == 0)\n",
    "        decay_grid = np.exp(-0.07 * distance_grid)\n",
    "\n",
    "        clipped_meta = src.meta.copy()\n",
    "        clipped_meta.update({\"driver\": \"GTiff\", \"height\": int(window.height), \"width\": int(window.width), \"transform\": transform, \"dtype\": rasterio.float32, \"count\": 1, \"compress\": 'lzw'})\n",
    "        output_path = os.path.join(tif_dir, f'exponential_decay_CO_roads_{tile_number}.tif')\n",
    "        with rasterio.open(output_path, 'w', **clipped_meta) as dst:\n",
    "            dst.write(decay_grid.astype(np.float32), 1)\n",
    "\n",
    "    src_ds = gdal.Open(output_path, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataRoads_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "    os.remove(output_path)\n",
    "\n",
    "    return output_resampled_path\n",
    "\n",
    "    del extent_data, bbox, graph, gdf\n",
    "    del window, transform, raster, shapes, burned, distance_grid, decay_grid\n",
    "    del clipped_meta, output_path\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "\n",
    "def generate_random_points(geometry, num_points):\n",
    "    points = []\n",
    "    min_x, min_y, max_x, max_y = geometry.bounds\n",
    "    while len(points) < num_points:\n",
    "        random_point = Point(np.random.uniform(min_x, max_x), np.random.uniform(min_y, max_y))\n",
    "        if random_point.within(geometry):\n",
    "            points.append(random_point)\n",
    "    return points\n",
    "\n",
    "    del bounds, crs, img, rect, buffered_rect, random_points\n",
    "    del gdf_points, gdf_points_wgs84, lat_long\n",
    "\n",
    "\n",
    "def process_chips(tif_path, tif_dir, lat_long, chip_size=128):\n",
    "    resampled_lidar_path = os.path.join(tif_dir, f\"output_resampled_dataLIDAR_{tile_number}.tif\")\n",
    "    resampled_dem_path = os.path.join(tif_dir, f\"output_resampled_dataDEM_{tile_number}.tif\")\n",
    "    resampled_rivers_path = os.path.join(tif_dir, f\"output_resampled_dataRivers_{tile_number}.tif\")\n",
    "    resampled_roads_path = os.path.join(tif_dir, f\"output_resampled_dataRoads_{tile_number}.tif\")\n",
    "\n",
    "    training_chips_dir = os.path.join(THEFOLDER, \"trainingchips\")\n",
    "    os.makedirs(training_chips_dir, exist_ok=True)\n",
    "\n",
    "    for i, (lat, lon) in enumerate(lat_long):\n",
    "        try:\n",
    "            paths = [resampled_lidar_path, resampled_dem_path, resampled_rivers_path, resampled_roads_path, tif_path]\n",
    "            labels = ['lidar', 'dem', 'rivers', 'roads', 'pcllabels']\n",
    "            \n",
    "            for path, label in zip(paths, labels):\n",
    "                with rasterio.open(path) as src:\n",
    "                    col, row = src.index(lon, lat)\n",
    "                    window = Window(col - chip_size // 2, row - chip_size // 2, chip_size, chip_size)\n",
    "                    chip_data = src.read(1, window=window)\n",
    "                    \n",
    "                    out_meta = src.meta.copy()\n",
    "                    out_meta.update({\n",
    "                        \"driver\": \"GTiff\",\n",
    "                        \"height\": chip_size,\n",
    "                        \"width\": chip_size,\n",
    "                        \"transform\": src.window_transform(window)\n",
    "                    })\n",
    "\n",
    "                    chip_output_dir = os.path.join(training_chips_dir, label)\n",
    "                    os.makedirs(chip_output_dir, exist_ok=True)\n",
    "                    \n",
    "                    chip_output_path = os.path.join(chip_output_dir, f\"{label.upper()}_Chip_{tile_number}_{i}.tif\")\n",
    "\n",
    "                    if chip_data.shape == (chip_size, chip_size):# and np.any(chip_data != src.nodata):\n",
    "                        with rasterio.open(chip_output_path, \"w\", **out_meta) as dest:\n",
    "                            dest.write(chip_data, 1)\n",
    "                    else:\n",
    "                        print(f\"Skipping {label} chip {i} because it is not properly shaped or is filled with nodata.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing chip {i}: {e}\")\n",
    "            \n",
    "    del resampled_lidar_path, resampled_dem_path, resampled_rivers_path, resampled_roads_path\n",
    "    del training_chips_dir, paths, labels, col, row, window, chip_data, out_meta, chip_output_dir, chip_output_path\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for tile_number in TILENUMBER:\n",
    "        tif_path = f\"{THEFOLDER}\\\\PCLTILES\\\\pcltile_{tile_number}.tif\"\n",
    "        tif_dir = f\"{THEFOLDER}\\\\TIFFOUTPUT\\\\{tile_number}\"\n",
    "        os.makedirs(tif_dir, exist_ok=True)\n",
    "\n",
    "        resampled_files = [\n",
    "            process_dem(tif_path, tif_dir, tile_number),\n",
    "            process_lidar(tif_path, tif_dir, tile_number),\n",
    "            process_rivers(tif_path, tif_dir, tile_number),\n",
    "            process_roads(tif_path, tif_dir, tile_number)\n",
    "        ]\n",
    "\n",
    "        delete_non_resampled_files([os.path.basename(f) for f in resampled_files], tif_dir)\n",
    "\n",
    "        # Generate random points within the tile bounds\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            bounds = src.bounds\n",
    "            crs = src.crs\n",
    "            img = src.read(1)\n",
    "\n",
    "        rect = box(bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "        buffered_rect = rect.buffer(-0.15)\n",
    "        random_points = generate_random_points(buffered_rect, 5000)\n",
    "        gdf_points = GeoDataFrame(geometry=random_points, crs=crs).to_crs(crs)\n",
    "        gdf_points_wgs84 = gdf_points.to_crs(epsg=4326)\n",
    "        lat_long = gdf_points_wgs84.geometry.apply(lambda geom: (geom.y, geom.x)).tolist()\n",
    "\n",
    "        process_chips(tif_path, tif_dir, lat_long)\n",
    "\n",
    "        print(f\"Processing for tile {tile_number} completed.\")\n",
    "\n",
    "    print(\"All processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75d74bf-09c6-4729-867d-13ad37a28e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import rasterio as rio\n",
    "# from rasterio.plot import show\n",
    "\n",
    "# # Define the directory containing the image chips\n",
    "# tile_dir = \"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GlobalPCL17\\\\TIFFOUTPUT\\\\75000-35000\"\n",
    "# output_path = r\"C:\\Users\\smdur\\OneDrive\\Desktop\\PCLCONUS\\figures\\trainingtile2.png\"\n",
    "\n",
    "# def plot_stacked_tiles_varying_alpha(tile_dir):\n",
    "#     # List all .tif files in the directory\n",
    "#     tile_files = sorted([f for f in os.listdir(tile_dir) if f.endswith('.tif')])\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    \n",
    "#     # Colormaps for each image to distinguish them\n",
    "#     colormaps = ['viridis', 'gray', 'inferno', 'magma']\n",
    "    \n",
    "#     n = len(tile_files)\n",
    "    \n",
    "#     for i, tile_file in enumerate(tile_files):\n",
    "#         tile_path = os.path.join(tile_dir, tile_file)\n",
    "#         with rio.open(tile_path) as src:\n",
    "#             img = src.read(1)\n",
    "#             transform = src.transform\n",
    "#             extent = rio.plot.plotting_extent(src)\n",
    "            \n",
    "#             # Alternate colormaps for each image\n",
    "#             cmap = colormaps[i % len(colormaps)]\n",
    "            \n",
    "#             # Adjust alpha dynamically (more for top layers, less for bottom)\n",
    "#             alpha = 0.7 - (0.4 * (i / (n - 1)))  # Alpha ranges from 0.7 to 0.3\n",
    "            \n",
    "#             # Plot each image with a different colormap and varying transparency\n",
    "#             show(img, ax=ax, transform=transform, extent=extent, cmap=cmap, alpha=alpha)\n",
    "\n",
    "#     # Set labels for x and y axes\n",
    "#     ax.set_xlabel('Longitude')\n",
    "#     ax.set_ylabel('Latitude')\n",
    "\n",
    "#     plt.savefig(output_path, dpi=300)  # Save the plot as a file\n",
    "#     plt.show()  # Display the plot\n",
    "\n",
    "# plot_stacked_tiles_varying_alpha(tile_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de10bbae-e510-4a43-8389-353fb07094db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import rasterio as rio\n",
    "# from rasterio.plot import show\n",
    "# import imageio\n",
    "# import numpy as np\n",
    "# from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "# # Define the directory containing the image chips\n",
    "# tile_dir = \"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GlobalPCL17\\\\TIFFOUTPUT\\\\75000-35000\"\n",
    "\n",
    "# def reproject_to_utm(src, dst_crs='EPSG:32633'):\n",
    "#     transform, width, height = calculate_default_transform(\n",
    "#         src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "#     kwargs = src.meta.copy()\n",
    "#     kwargs.update({\n",
    "#         'crs': dst_crs,\n",
    "#         'transform': transform,\n",
    "#         'width': width,\n",
    "#         'height': height\n",
    "#     })\n",
    "\n",
    "#     data = np.zeros((height, width), dtype=rio.uint8)\n",
    "#     reproject(\n",
    "#         source=rio.band(src, 1),\n",
    "#         destination=data,\n",
    "#         src_transform=src.transform,\n",
    "#         src_crs=src.crs,\n",
    "#         dst_transform=transform,\n",
    "#         dst_crs=dst_crs,\n",
    "#         resampling=Resampling.nearest)\n",
    "#     return data, transform\n",
    "\n",
    "# def plot_stacked_tiles_varying_alpha(tile_dir, output_gif='C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GlobalPCL17\\\\scanning_box2.gif'):\n",
    "#     # List all .tif files in the directory\n",
    "#     tile_files = sorted([f for f in os.listdir(tile_dir) if f.endswith('.tif')])\n",
    "    \n",
    "#     # Load the first tile to get metadata and use it to set bounds correctly\n",
    "#     with rio.open(os.path.join(tile_dir, tile_files[0])) as src:\n",
    "#         meta = src.meta.copy()\n",
    "#         img, transform = reproject_to_utm(src)  # Reproject first image to get metadata\n",
    "#         bounds = src.bounds\n",
    "\n",
    "#     box_width, box_height = 512, 512  # Adjust as necessary\n",
    "#     step_size = 512  # Adjust as necessary\n",
    "#     frames = []\n",
    "\n",
    "#     # Create a plot for each position of the scanning box\n",
    "#     for x in np.arange(bounds.left, bounds.right, step_size * transform[0]):\n",
    "#         for y in np.arange(bounds.bottom, bounds.top, step_size * abs(transform[4])):\n",
    "#             fig, ax = plt.subplots(figsize=(12, 12))\n",
    "#             # Plot each tile\n",
    "#             for i, tile_file in enumerate(tile_files):\n",
    "#                 tile_path = os.path.join(tile_dir, tile_file)\n",
    "#                 with rio.open(tile_path) as src:\n",
    "#                     img, transform = reproject_to_utm(src)  # Reproject each image\n",
    "#                     cmap = ['viridis', 'gray', 'inferno', 'magma'][i % len(tile_files)]\n",
    "#                     alpha = 0.7 - (0.4 * (i / (len(tile_files) - 1)))\n",
    "#                     show(img, ax=ax, transform=transform, cmap=cmap, alpha=alpha)\n",
    "\n",
    "#             rect = plt.Rectangle((x, y), box_width, box_height, linewidth=3, edgecolor='red', facecolor='none')\n",
    "#             ax.add_patch(rect)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "#             plt.title(\"Scanning Spatial Image Chips\")\n",
    "#             fig.canvas.draw()\n",
    "#             frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "#             frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "#             frames.append(frame)\n",
    "#             plt.close(fig)\n",
    "\n",
    "#     imageio.mimsave(output_gif, frames, fps=40)\n",
    "\n",
    "# plot_stacked_tiles_varying_alpha(tile_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2a75c-777b-46a4-881b-676ff1baeb28",
   "metadata": {},
   "source": [
    "# Load chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d512a5-ccd6-48f1-be24-aec0cefce59f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\lidar\n",
      "Loaded 10000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\lidar\n",
      "Loaded 15000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\lidar\n",
      "Loaded 5000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\dem\n",
      "Loaded 10000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\dem\n",
      "Loaded 15000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\dem\n",
      "Loaded 5000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\roads\n",
      "Loaded 10000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\roads\n",
      "Loaded 15000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\roads\n",
      "Loaded 5000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\rivers\n",
      "Loaded 10000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\rivers\n",
      "Loaded 15000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\rivers\n",
      "Loaded 5000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\pcllabels\n",
      "Loaded 10000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\pcllabels\n",
      "Loaded 15000 images from C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\trainingchips\\pcllabels\n",
      "HAG max value: 37.0\n",
      "DEM max value: 4379.1279296875\n",
      "Roads max value: 1.0\n",
      "Rivers max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import rasterio\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# training_chips_dir = os.path.join(THEFOLDER, \"trainingchips\")\n",
    "\n",
    "# # Paths to datasets\n",
    "# featurepath1 = os.path.join(training_chips_dir, \"lidar\")\n",
    "# featurepath2 = os.path.join(training_chips_dir, \"dem\")\n",
    "# featurepath3 = os.path.join(training_chips_dir, \"roads\")\n",
    "# featurepath4 = os.path.join(training_chips_dir, \"rivers\")\n",
    "# labelspath = os.path.join(training_chips_dir, \"pcllabels\")\n",
    "\n",
    "# # Function to load GeoTIFF images as numpy arrays\n",
    "# def load_geotiff(path):\n",
    "#     with rasterio.open(path) as src:\n",
    "#         return src.read(1)\n",
    "\n",
    "# # Function to load and print progress\n",
    "# def load_images(path):\n",
    "#     files = [f for f in os.listdir(path) if f.endswith('.tif')]\n",
    "#     images = []\n",
    "#     for i, f in enumerate(files):\n",
    "#         images.append(load_geotiff(os.path.join(path, f)))\n",
    "#         if (i + 1) % 5000 == 0:\n",
    "#             print(f\"Loaded {i + 1} images from {path}\")\n",
    "#     return images\n",
    "\n",
    "# # Load datasets\n",
    "# hag_images = load_images(featurepath1)\n",
    "# dem_images = load_images(featurepath2)\n",
    "# roads_images = load_images(featurepath3)\n",
    "# rivers_images = load_images(featurepath4)\n",
    "# label_images = load_images(labelspath)\n",
    "\n",
    "# # Convert lists to numpy arrays\n",
    "# hag_images = np.array(hag_images).astype('float32')\n",
    "# dem_images = np.array(dem_images).astype('float32')\n",
    "# roads_images = np.array(roads_images).astype('float32')\n",
    "# rivers_images = np.array(rivers_images).astype('float32')\n",
    "# label_images = np.array(label_images).astype('float32')\n",
    "\n",
    "# # Normalize images independently\n",
    "# hag_max = hag_images.max()\n",
    "# dem_max = dem_images.max()\n",
    "# roads_max = roads_images.max()\n",
    "# rivers_max = rivers_images.max()\n",
    "\n",
    "# hag_images /= hag_max\n",
    "# dem_images /= dem_max\n",
    "# roads_images /= roads_max\n",
    "# rivers_images /= rivers_max\n",
    "\n",
    "# print(f\"HAG max value: {hag_max}\")\n",
    "# print(f\"DEM max value: {dem_max}\")\n",
    "# print(f\"Roads max value: {roads_max}\")\n",
    "# print(f\"Rivers max value: {rivers_max}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "training_chips_dir = os.path.join(THEFOLDER, \"trainingchips\")\n",
    "\n",
    "# Paths to datasets\n",
    "featurepath1 = os.path.join(training_chips_dir, \"lidar\")\n",
    "featurepath2 = os.path.join(training_chips_dir, \"dem\")\n",
    "featurepath3 = os.path.join(training_chips_dir, \"roads\")\n",
    "featurepath4 = os.path.join(training_chips_dir, \"rivers\")\n",
    "labelspath = os.path.join(training_chips_dir, \"pcllabels\")\n",
    "\n",
    "# Function to load GeoTIFF images as numpy arrays\n",
    "def load_geotiff(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1)\n",
    "        if np.all(data == 0):\n",
    "            return None  # Return None if the image is all zeros\n",
    "        return data\n",
    "\n",
    "# Function to load and print progress\n",
    "def load_images(path, skip_zeros=False):\n",
    "    files = [f for f in os.listdir(path) if f.endswith('.tif')]\n",
    "    images = []\n",
    "    for i, f in enumerate(files):\n",
    "        image = load_geotiff(os.path.join(path, f))\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "        elif skip_zeros:\n",
    "            print(f\"Skipping {f} because it is all zeros\")\n",
    "        if (i + 1) % 5000 == 0:\n",
    "            print(f\"Loaded {i + 1} images from {path}\")\n",
    "    return images\n",
    "\n",
    "# Load datasets\n",
    "hag_images = load_images(featurepath1)\n",
    "dem_images = load_images(featurepath2, skip_zeros=True)  # Skip DEM images that are all zeros\n",
    "roads_images = load_images(featurepath3)\n",
    "rivers_images = load_images(featurepath4)\n",
    "label_images = load_images(labelspath)\n",
    "\n",
    "# Ensure all datasets have the same number of images\n",
    "min_length = min(len(hag_images), len(dem_images), len(roads_images), len(rivers_images), len(label_images))\n",
    "hag_images = hag_images[:min_length]\n",
    "dem_images = dem_images[:min_length]\n",
    "roads_images = roads_images[:min_length]\n",
    "rivers_images = rivers_images[:min_length]\n",
    "label_images = label_images[:min_length]\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "hag_images = np.array(hag_images).astype('float32')\n",
    "dem_images = np.array(dem_images).astype('float32')\n",
    "roads_images = np.array(roads_images).astype('float32')\n",
    "rivers_images = np.array(rivers_images).astype('float32')\n",
    "label_images = np.array(label_images).astype('float32')\n",
    "\n",
    "# Normalize images independently\n",
    "hag_max = hag_images.max()\n",
    "dem_max = dem_images.max()\n",
    "roads_max = roads_images.max()\n",
    "rivers_max = rivers_images.max()\n",
    "\n",
    "hag_images /= hag_max\n",
    "dem_images /= dem_max\n",
    "roads_images /= roads_max\n",
    "rivers_images /= rivers_max\n",
    "\n",
    "print(f\"HAG max value: {hag_max}\")\n",
    "print(f\"DEM max value: {dem_max}\")\n",
    "print(f\"Roads max value: {roads_max}\")\n",
    "print(f\"Rivers max value: {rivers_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a205ea0-0aef-4972-8260-e94505020a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # Set the environment variable before importing gdal\n",
    "# os.environ['USE_PATH_FOR_GDAL_PYTHON'] = 'YES'\n",
    "# os.add_dll_directory(os.path.join(os.getenv('CONDA_PREFIX'), 'Library', 'bin'))\n",
    "\n",
    "# import rasterio\n",
    "# import numpy as np\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# training_chips_dir = os.path.join(THEFOLDER, \"trainingchips\")\n",
    "\n",
    "# # Paths to datasets\n",
    "# featurepath1 = os.path.join(training_chips_dir, \"lidar\")\n",
    "# featurepath2 = os.path.join(training_chips_dir, \"dem\")\n",
    "# featurepath3 = os.path.join(training_chips_dir, \"roads\")\n",
    "# featurepath4 = os.path.join(training_chips_dir, \"rivers\")\n",
    "# labelspath = os.path.join(training_chips_dir, \"pcllabels\")\n",
    "\n",
    "# # Function to load GeoTIFF images as numpy arrays\n",
    "# def load_geotiff(path):\n",
    "#     with rasterio.open(path) as src:\n",
    "#         return src.read(1)\n",
    "\n",
    "# # Function to load images in parallel with progress printing\n",
    "# def load_images(path):\n",
    "#     files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith('.tif')]\n",
    "#     num_files = len(files)\n",
    "#     images = []\n",
    "\n",
    "#     def load_and_count(file):\n",
    "#         image = load_geotiff(file)\n",
    "#         if (load_and_count.counter + 1) % 5000 == 0:\n",
    "#             print(f\"Loaded {load_and_count.counter + 1} images from {path}\")\n",
    "#         load_and_count.counter += 1\n",
    "#         return image\n",
    "\n",
    "#     load_and_count.counter = 0\n",
    "\n",
    "#     max_workers = min(32, os.cpu_count() + 4)  # Default value if not specified\n",
    "\n",
    "#     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#         images = list(executor.map(load_and_count, files))\n",
    "\n",
    "#     return np.array(images).astype('float32')\n",
    "\n",
    "# # Load datasets\n",
    "# hag_images = load_images(featurepath1)\n",
    "# dem_images = load_images(featurepath2)\n",
    "# roads_images = load_images(featurepath3)\n",
    "# rivers_images = load_images(featurepath4)\n",
    "# label_images = load_images(labelspath)\n",
    "\n",
    "# # Normalize images independently\n",
    "# hag_max = hag_images.max()\n",
    "# dem_max = dem_images.max()\n",
    "# roads_max = roads_images.max()\n",
    "# rivers_max = rivers_images.max()\n",
    "\n",
    "# hag_images /= hag_max\n",
    "# dem_images /= dem_max\n",
    "# roads_images /= roads_max\n",
    "# rivers_images /= rivers_max\n",
    "\n",
    "\n",
    "# print(f\"HAG max value: {hag_max}\")\n",
    "# print(f\"DEM max value: {dem_max}\")\n",
    "# print(f\"Roads max value: {roads_max}\")\n",
    "# print(f\"Rivers max value: {rivers_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f701ce-82e3-44f8-aaa1-fa729820d7ff",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43839a1d-07d4-4c5b-a82d-4231b4ffedcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature images shape: (14298, 128, 128, 4)\n",
      "Label images shape: (14298, 128, 128, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 4)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 128, 128, 64)         2368      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 64)         36928     ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 64, 64, 64)           0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 64, 64, 64)           0         ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 128)          73856     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 128)          147584    ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 128)          0         ['conv2d_3[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 32, 32, 128)          0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 256)          295168    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 256)          590080    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 16, 16, 256)          0         ['conv2d_5[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 16, 16, 256)          0         ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 16, 16, 512)          1180160   ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 512)          2359808   ['conv2d_6[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 8, 8, 512)            0         ['conv2d_7[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 8, 8, 512)            0         ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 8, 8, 1024)           4719616   ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 1024)           9438208   ['conv2d_8[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2  (None, 16, 16, 1024)         0         ['conv2d_9[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 16, 1536)         0         ['up_sampling2d[0][0]',       \n",
      "                                                                     'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 512)          7078400   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 512)          2359808   ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSamplin  (None, 32, 32, 512)          0         ['conv2d_11[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 32, 32, 768)          0         ['up_sampling2d_1[0][0]',     \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 32, 32, 256)          1769728   ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 32, 32, 256)          590080    ['conv2d_12[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSamplin  (None, 64, 64, 256)          0         ['conv2d_13[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 64, 384)          0         ['up_sampling2d_2[0][0]',     \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 64, 64, 128)          442496    ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 64, 64, 128)          147584    ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSamplin  (None, 128, 128, 128)        0         ['conv2d_15[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 128, 128, 192)        0         ['up_sampling2d_3[0][0]',     \n",
      " )                                                                   'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 128, 128, 64)         110656    ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 128, 128, 64)         36928     ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 128, 128, 1)          65        ['conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 128, 128, 1)          0         ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31379521 (119.70 MB)\n",
      "Trainable params: 31379521 (119.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "157/157 [==============================] - 2366s 15s/step - loss: 1.6614 - mean_squared_error: 1.6614 - val_loss: 0.0552 - val_mean_squared_error: 0.0552\n",
      "Training loss: [1.6614407300949097]\n",
      "Validation loss: [0.05517296865582466]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1744"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# # Stack features along the last dimension\n",
    "# feature_images = np.stack((hag_images, dem_images, roads_images, rivers_images), axis=-1)\n",
    "\n",
    "# # Free up memory by deleting the original arrays\n",
    "# # del hag_images\n",
    "# # del dem_images\n",
    "# # del roads_images\n",
    "# # del rivers_images\n",
    "\n",
    "# # If you want to ensure that the memory is freed immediately\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# CHIP_SIZE=128\n",
    "\n",
    "# # Normalize labels if they range from 0 to 100\n",
    "# label_images /= 100\n",
    "\n",
    "# # Reshape labels for CNN input\n",
    "# label_images = np.expand_dims(label_images, axis=-1)\n",
    "\n",
    "# # Define the CNN model\n",
    "# model = Sequential([\n",
    "#     #Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 4)),\n",
    "#     Conv2D(16, (3, 3), activation='relu', input_shape=(CHIP_SIZE, CHIP_SIZE, 4)),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.25),\n",
    "#     Conv2D(32, (3, 3), activation='relu'),\n",
    "#     MaxPooling2D((2, 2)),\n",
    "#     Dropout(0.25),\n",
    "#     Conv2D(64, (3, 3), activation='relu'),\n",
    "#     Flatten(),\n",
    "#     Dropout(0.5),\n",
    "#     #Dense(128 * 128, activation='sigmoid'),\n",
    "#     #tf.keras.layers.Reshape((128, 128, 1))\n",
    "#     Dense(CHIP_SIZE * CHIP_SIZE, activation='sigmoid'),\n",
    "#     tf.keras.layers.Reshape((CHIP_SIZE, CHIP_SIZE, 1))\n",
    "# ])\n",
    "\n",
    "# # # Define custom weights for each feature\n",
    "# # weights = np.array([1.0, 0.8, 0.5, 0.3])  \n",
    "# # sample_weights = np.dot(feature_images, weights)\n",
    "\n",
    "# lr = 0.0005\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# # Compile and train the model with sample weights\n",
    "# model.compile(optimizer=optimizer, loss='mse')\n",
    "# model.fit(feature_images, label_images, batch_size=64, epochs=10, validation_split=0.3)#, sample_weight=sample_weights)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Stack features along the last dimension\n",
    "feature_images = np.stack((hag_images, dem_images, roads_images, rivers_images), axis=-1)\n",
    "\n",
    "# Free up memory by deleting the original arrays\n",
    "del hag_images, dem_images, roads_images, rivers_images\n",
    "gc.collect()\n",
    "\n",
    "CHIP_SIZE = 128\n",
    "\n",
    "# Normalize labels if they range from 0 to 100\n",
    "label_images /= 100\n",
    "\n",
    "# Reshape labels for CNN input\n",
    "label_images = np.expand_dims(label_images, axis=-1)\n",
    "\n",
    "# Check shapes of input and label data\n",
    "print(\"Feature images shape:\", feature_images.shape)\n",
    "print(\"Label images shape:\", label_images.shape)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout, Dense, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def unet_model(input_size=(128, 128, 4)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    # Decoder\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    up6 = Concatenate()([up6, conv4])\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = Concatenate()([up7, conv3])\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    \n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up8 = Concatenate()([up8, conv2])\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    \n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    up9 = Concatenate()([up9, conv1])\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    \n",
    "    # Final output layer\n",
    "    conv10 = Conv2D(1, (1, 1), activation='linear')(conv9)\n",
    "    \n",
    "    # Reshape layer\n",
    "    output = Reshape((input_size[0], input_size[1], 1))(conv10)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Instantiate the U-Net model\n",
    "chip_size = 128\n",
    "model = unet_model(input_size=(chip_size, chip_size, 4))\n",
    "\n",
    "# Compile the model\n",
    "lr = 0.001\n",
    "optimizer = Adam(learning_rate=lr)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Example training code (you should adjust this as needed)\n",
    "# history = model.fit(feature_images, label_images, batch_size=64, epochs=10, validation_split=0.3)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(feature_images, label_images, batch_size=64, epochs=1, validation_split=0.3)\n",
    "\n",
    "# Check if the model is learning\n",
    "print(\"Training loss:\", history.history['loss'])\n",
    "print(\"Validation loss:\", history.history['val_loss'])\n",
    "\n",
    "# Clean up\n",
    "del feature_images, label_images\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264af860-99d8-430c-8cea-181eef04ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import numpy as np\n",
    "\n",
    "# # Collect garbage\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# CHIP_SIZE = 128\n",
    "\n",
    "# # Assuming hag_images, dem_images, roads_images, and rivers_images are numpy arrays\n",
    "# # Stack features along the last dimension\n",
    "# feature_images = np.stack((hag_images, dem_images, roads_images, rivers_images), axis=-1)\n",
    "\n",
    "# # Normalize labels if they range from 0 to 100\n",
    "# label_images /= 100\n",
    "\n",
    "# # Reshape labels for CNN input\n",
    "# label_images = np.expand_dims(label_images, axis=-1)\n",
    "\n",
    "# # Convert numpy arrays to PyTorch tensors\n",
    "# feature_images = torch.tensor(feature_images, dtype=torch.float32)\n",
    "# label_images = torch.tensor(label_images, dtype=torch.float32)\n",
    "\n",
    "# # Permute the dimensions of feature_images to (N, C, H, W)\n",
    "# feature_images = feature_images.permute(0, 3, 1, 2)\n",
    "\n",
    "# # Remove the extra dimension from label_images\n",
    "# label_images = label_images.squeeze()\n",
    "\n",
    "# # Define the dataset\n",
    "# dataset = TensorDataset(feature_images, label_images)\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# train_size = int(0.7 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Define the dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# # Define the CNN model\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, chip_size):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(4, 16, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.dropout1 = nn.Dropout(0.25)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(64 * (chip_size // 4) * (chip_size // 4), chip_size * chip_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.reshape = lambda x: x.view(-1, chip_size, chip_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = nn.ReLU()(self.conv3(x))\n",
    "#         x = x.view(-1, 64 * (CHIP_SIZE // 4) * (CHIP_SIZE // 4))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.sigmoid(self.fc1(x))\n",
    "#         x = self.reshape(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model, define the optimizer and loss function\n",
    "# model = CNNModel(CHIP_SIZE)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0006)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # Training loop\n",
    "# epochs = 3\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         # Add an extra dimension to labels to match the output shape\n",
    "#         labels = labels.unsqueeze(1)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 100 == 99:  # Print every 100 batches\n",
    "#             print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.4f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             # Add an extra dimension to labels to match the output shape\n",
    "#             labels = labels.unsqueeze(1)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "#     print(f'Epoch {epoch + 1}, Validation Loss: {val_loss / len(val_loader):.4f}')\n",
    "\n",
    "# print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55532cdf-36fc-4727-a735-46ff91668790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import numpy as np\n",
    "\n",
    "# # Collect garbage\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    "# CHIP_SIZE = 128\n",
    "\n",
    "# # Assuming hag_images, dem_images, roads_images, and rivers_images are numpy arrays\n",
    "# # Stack features along the last dimension\n",
    "# feature_images = np.stack((hag_images, dem_images, roads_images, rivers_images), axis=-1)\n",
    "\n",
    "# # Normalize labels if they range from 0 to 100\n",
    "# label_images /= 100\n",
    "\n",
    "# # Reshape labels for CNN input\n",
    "# label_images = np.expand_dims(label_images, axis=-1)\n",
    "\n",
    "# # Convert numpy arrays to PyTorch tensors\n",
    "# feature_images = torch.tensor(feature_images, dtype=torch.float32)\n",
    "# label_images = torch.tensor(label_images, dtype=torch.float32)\n",
    "\n",
    "# # Permute the dimensions of feature_images to (N, C, H, W)\n",
    "# feature_images = feature_images.permute(0, 3, 1, 2)\n",
    "\n",
    "# # Remove the extra dimension from label_images\n",
    "# label_images = label_images.squeeze(-1)\n",
    "\n",
    "# # Define the dataset\n",
    "# dataset = TensorDataset(feature_images, label_images)\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# train_size = int(0.7 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Define the dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# # Define the CNN model\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, chip_size):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(4, 16, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.dropout1 = nn.Dropout(0.25)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(64 * (chip_size // 4) * (chip_size // 4), chip_size * chip_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.reshape = lambda x: x.view(-1, chip_size, chip_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = nn.ReLU()(self.conv3(x))\n",
    "#         x = x.view(-1, 64 * (CHIP_SIZE // 4) * (CHIP_SIZE // 4))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.sigmoid(self.fc1(x))\n",
    "#         x = self.reshape(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model, define the optimizer and loss function\n",
    "# model = CNNModel(CHIP_SIZE)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0006)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # Training loop\n",
    "# epochs = 1\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 100 == 99:  # Print every 100 batches\n",
    "#             print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.4f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "#     print(f'Epoch {epoch + 1}, Validation Loss: {val_loss / len(val_loader):.4f}')\n",
    "\n",
    "# print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73cf6a02-dfda-4f9e-8b72-22e60affe5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think this ran correctly \n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "# import numpy as np\n",
    "# import gc\n",
    "# # Important\n",
    "# import os\n",
    "# from osgeo import gdal\n",
    "\n",
    "\n",
    "# # Function to clear memory\n",
    "# def clear_memory():\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# # Set chip size\n",
    "# CHIP_SIZE = 128\n",
    "\n",
    "# # # Example placeholder arrays (replace with your actual data)\n",
    "# # hag_images = np.random.rand(10, CHIP_SIZE, CHIP_SIZE)\n",
    "# # dem_images = np.random.rand(10, CHIP_SIZE, CHIP_SIZE)\n",
    "# # roads_images = np.random.rand(10, CHIP_SIZE, CHIP_SIZE)\n",
    "# # rivers_images = np.random.rand(10, CHIP_SIZE, CHIP_SIZE)\n",
    "# # label_images = np.random.rand(10, CHIP_SIZE, CHIP_SIZE)\n",
    "\n",
    "# # Normalize labels if they range from 0 to 100\n",
    "# label_images /= 100\n",
    "\n",
    "# # Stack features along the last dimension\n",
    "# feature_images = np.stack((hag_images, dem_images, roads_images, rivers_images), axis=-1)\n",
    "\n",
    "# # Reshape labels for CNN input\n",
    "# label_images = np.expand_dims(label_images, axis=-1)\n",
    "\n",
    "# # Convert numpy arrays to PyTorch tensors\n",
    "# feature_images = torch.tensor(feature_images, dtype=torch.float32)\n",
    "# label_images = torch.tensor(label_images, dtype=torch.float32)\n",
    "\n",
    "# # Permute the dimensions of feature_images to (N, C, H, W)\n",
    "# feature_images = feature_images.permute(0, 3, 1, 2)\n",
    "\n",
    "# # Remove the extra dimension from label_images\n",
    "# label_images = label_images.squeeze(-1)\n",
    "\n",
    "# # Define the dataset\n",
    "# dataset = TensorDataset(feature_images, label_images)\n",
    "\n",
    "# # Split the dataset into training and validation sets\n",
    "# train_size = int(0.7 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# # Define the dataloaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# # Define the CNN model\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, chip_size):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(4, 16, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.dropout1 = nn.Dropout(0.25)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.dropout2 = nn.Dropout(0.5)\n",
    "#         self.fc1 = nn.Linear(64 * (chip_size // 4) * (chip_size // 4), chip_size * chip_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "#         self.reshape = lambda x: x.view(-1, chip_size, chip_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "#         x = self.dropout1(x)\n",
    "#         x = nn.ReLU()(self.conv3(x))\n",
    "#         x = x.view(-1, 64 * (CHIP_SIZE // 4) * (CHIP_SIZE // 4))\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.sigmoid(self.fc1(x))\n",
    "#         x = self.reshape(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model, define the optimizer and loss function\n",
    "# model = CNNModel(CHIP_SIZE)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0006)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# # Training loop\n",
    "# epochs = 1\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 100 == 99:  # Print every 100 batches\n",
    "#             print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100:.4f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "#     # Validation loop\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in val_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             val_loss += loss.item()\n",
    "#     print(f'Epoch {epoch + 1}, Validation Loss: {val_loss / len(val_loader):.4f}')\n",
    "\n",
    "# print('Finished Training')\n",
    "\n",
    "# # Clear memory after training\n",
    "# clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68a2c457-181d-4c00-9664-15579bc82b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d96cc7a-ff9e-4705-b91d-0e9232bd178c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for lidar completed.\n",
      "Processing for dem completed.\n",
      "Processing for roads completed.\n",
      "Processing for rivers completed.\n",
      "Processing for tile 70000-40000 completed.\n",
      "All processing completed.\n"
     ]
    }
   ],
   "source": [
    "# MAKE DATA\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from osgeo import gdal\n",
    "import rioxarray\n",
    "import planetary_computer\n",
    "from pystac_client import Client\n",
    "import osmnx as ox\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.windows import from_bounds, Window\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "from shapely.geometry import box\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "import rasterio as rio\n",
    "from itertools import product\n",
    "from rasterio import windows\n",
    "\n",
    "TILENUMBER = ['70000-40000']\n",
    "CHIP_SIZE = 128  \n",
    "\n",
    "def delete_non_resampled_files(resampled_files, tif_dir):\n",
    "    for file in os.listdir(tif_dir):\n",
    "        if file not in resampled_files and file.endswith('.tif'):\n",
    "            file_path = os.path.join(tif_dir, file)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to delete {file_path}: {e}\")\n",
    "\n",
    "def process_dem(tif_path, tif_dir, tile_number):\n",
    "    tif_data = rioxarray.open_rasterio(tif_path)\n",
    "    bbox_of_interest = tif_data.rio.bounds()\n",
    "    catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "    search = catalog.search(collections=[\"cop-dem-glo-30\"], bbox=bbox_of_interest)\n",
    "    items = list(search.get_items())\n",
    "    \n",
    "    def process_item(item, idx):\n",
    "        signed_asset = planetary_computer.sign(item.assets[\"data\"])\n",
    "        data = rioxarray.open_rasterio(signed_asset.href).squeeze().drop(\"band\")\n",
    "        data.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "        output_tif_path = os.path.join(tif_dir, f\"output_dataDEM_{idx}.tif\")\n",
    "        data.rio.to_raster(output_tif_path)\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        for i, item in enumerate(items):\n",
    "            executor.submit(process_item, item, i)\n",
    "\n",
    "    output_tif = os.path.join(tif_dir, f\"outputtile_DEM_{tile_number}.tif\")\n",
    "    merge_command = [\n",
    "        \"python\", \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "        \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "        \"-o\", output_tif,\n",
    "        \"-n\", \"-9999\", \"-a_nodata\", \"-9999\"] + glob.glob(os.path.join(tif_dir, \"output_dataDEM_*.tif\"))\n",
    "\n",
    "    process_hag = subprocess.run(merge_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if process_hag.returncode != 0:\n",
    "        print(f\"Error in merging DEM: {process_hag.stderr}\")\n",
    "        return None\n",
    "\n",
    "    src_ds = gdal.Open(output_tif, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataDEM_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "\n",
    "    os.remove(output_tif)\n",
    "    for tif in glob.glob(os.path.join(tif_dir, \"output_dataDEM_*.tif\")):\n",
    "        try:\n",
    "            os.remove(tif)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {tif}: {e}\")\n",
    "\n",
    "    return output_resampled_path\n",
    "    del tif_data, bbox_of_interest, catalog, search, items\n",
    "    del output_tif, merge_command, process_hag\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "def process_lidar(tif_path, tif_dir, tile_number):\n",
    "    lidar_dir = r\"C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalData\\LIDAR2\"\n",
    "    lidar_tifs = glob.glob(os.path.join(lidar_dir, \"*.tif\"))\n",
    "\n",
    "    # Get the bounding box of the input tif_path\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        bbox = src.bounds\n",
    "        input_geom = box(bbox.left, bbox.bottom, bbox.right, bbox.top)\n",
    "\n",
    "    # Find overlapping LIDAR tiles\n",
    "    overlapping_tifs = []\n",
    "    for tif in lidar_tifs:\n",
    "        with rasterio.open(tif) as src:\n",
    "            lidar_bbox = src.bounds\n",
    "            lidar_geom = box(lidar_bbox.left, lidar_bbox.bottom, lidar_bbox.right, lidar_bbox.top)\n",
    "            if input_geom.intersects(lidar_geom):\n",
    "                overlapping_tifs.append(tif)\n",
    "\n",
    "    if not overlapping_tifs:\n",
    "        print(f\"No overlapping LIDAR tiles found for {tile_number}\")\n",
    "        return None\n",
    "\n",
    "    output_tif = os.path.join(tif_dir, f\"outputtile_lidar_{tile_number}.tif\")\n",
    "    merge_command = [\n",
    "        \"python\", \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "        \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "        \"-o\", output_tif,\n",
    "        \"-n\", \"255\", \"-a_nodata\", \"255\"] + overlapping_tifs\n",
    "\n",
    "    process_hag = subprocess.run(merge_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    if process_hag.returncode != 0:\n",
    "        print(f\"Error in merging LIDAR: {process_hag.stderr}\")\n",
    "        return None\n",
    "\n",
    "    src_ds = gdal.Open(output_tif, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataLIDAR_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "\n",
    "    os.remove(output_tif)\n",
    "    return output_resampled_path\n",
    "    del lidar_tifs, bbox, input_geom, overlapping_tifs, lidar_bbox, lidar_geom\n",
    "    del output_tif, merge_command, process_hag\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "def process_rivers(tif_path, tif_dir, tile_number):\n",
    "    dem_data = rioxarray.open_rasterio(tif_path)\n",
    "    bbox = dem_data.rio.bounds()\n",
    "    custom_filter = '[\"waterway\"~\"river\"]'\n",
    "    graph = ox.graph_from_bbox(bbox[3], bbox[1], bbox[2], bbox[0], custom_filter=custom_filter, simplify=True, retain_all=True, truncate_by_edge=True)\n",
    "    gdf = ox.graph_to_gdfs(graph, nodes=False)\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        window = from_bounds(*src.bounds, src.transform)\n",
    "        transform = rasterio.windows.transform(window, src.transform)\n",
    "        raster = np.zeros((int(window.height), int(window.width)), dtype=np.uint8)\n",
    "        shapes = ((geom, 1) for geom in gdf['geometry'])\n",
    "        burned = rasterize(shapes, out=raster, fill=0, transform=transform, all_touched=True)\n",
    "        distance_grid = scipy.ndimage.distance_transform_edt(burned == 0)\n",
    "        decay_grid = np.exp(-0.07 * distance_grid)\n",
    "\n",
    "        clipped_meta = src.meta.copy()\n",
    "        clipped_meta.update({\"driver\": \"GTiff\", \"height\": int(window.height), \"width\": int(window.width), \"transform\": transform, \"dtype\": rasterio.float32, \"count\": 1, \"compress\": 'lzw'})\n",
    "        output_path = os.path.join(tif_dir, f'exponential_decay_CO_river_{tile_number}.tif')\n",
    "        with rasterio.open(output_path, 'w', **clipped_meta) as dst:\n",
    "            dst.write(decay_grid.astype(np.float32), 1)\n",
    "\n",
    "    src_ds = gdal.Open(output_path, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataRivers_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "    os.remove(output_path)\n",
    "\n",
    "    return output_resampled_path\n",
    "    del dem_data, bbox, custom_filter, graph, gdf\n",
    "    del window, transform, raster, shapes, burned, distance_grid, decay_grid\n",
    "    del clipped_meta, output_path\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "def process_roads(tif_path, tif_dir, tile_number):\n",
    "    extent_data = rioxarray.open_rasterio(tif_path)\n",
    "    bbox = extent_data.rio.bounds()\n",
    "    graph = ox.graph_from_bbox(bbox[3], bbox[1], bbox[2], bbox[0], network_type='drive', simplify=True)\n",
    "    gdf = ox.graph_to_gdfs(graph, nodes=False)\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        window = from_bounds(*src.bounds, src.transform)\n",
    "        transform = rasterio.windows.transform(window, src.transform)\n",
    "        raster = np.zeros((int(window.height), int(window.width)), dtype=np.uint8)\n",
    "        shapes = ((geom, 1) for geom in gdf['geometry'])\n",
    "        burned = rasterize(shapes, out=raster, fill=0, transform=transform, all_touched=True)\n",
    "        distance_grid = scipy.ndimage.distance_transform_edt(burned == 0)\n",
    "        decay_grid = np.exp(-0.07 * distance_grid)\n",
    "\n",
    "        clipped_meta = src.meta.copy()\n",
    "        clipped_meta.update({\"driver\": \"GTiff\", \"height\": int(window.height), \"width\": int(window.width), \"transform\": transform, \"dtype\": rasterio.float32, \"count\": 1, \"compress\": 'lzw'})\n",
    "        output_path = os.path.join(tif_dir, f'exponential_decay_CO_roads_{tile_number}.tif')\n",
    "        with rasterio.open(output_path, 'w', **clipped_meta) as dst:\n",
    "            dst.write(decay_grid.astype(np.float32), 1)\n",
    "\n",
    "    src_ds = gdal.Open(output_path, gdal.GA_ReadOnly)\n",
    "    target_ds = gdal.Open(tif_path, gdal.GA_ReadOnly)\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    output_resampled_path = os.path.join(tif_dir, f\"output_resampled_dataRoads_{tile_number}.tif\")\n",
    "    out_ds = driver.Create(output_resampled_path, target_ds.RasterXSize, target_ds.RasterYSize, 1, src_ds.GetRasterBand(1).DataType)\n",
    "    out_ds.SetGeoTransform(target_ds.GetGeoTransform())\n",
    "    out_ds.SetProjection(target_ds.GetProjection())\n",
    "    gdal.ReprojectImage(src_ds, out_ds, src_ds.GetProjection(), target_ds.GetProjection(), gdal.GRA_Bilinear)\n",
    "    src_ds, target_ds, out_ds = None, None, None\n",
    "    os.remove(output_path)\n",
    "\n",
    "    return output_resampled_path\n",
    "    del extent_data, bbox, graph, gdf\n",
    "    del window, transform, raster, shapes, burned, distance_grid, decay_grid\n",
    "    del clipped_meta, output_path\n",
    "    del src_ds, target_ds, driver, output_resampled_path\n",
    "\n",
    "# OFFSET_X = 20  # Horizontal offset\n",
    "# OFFSET_Y = 20  # Vertical offset\n",
    "\n",
    "def get_tiles(ds, width=CHIP_SIZE, height=CHIP_SIZE):\n",
    "    offset_x = 128  # Horizontal offset\n",
    "    offset_y = 128 # Vertical offset\n",
    "\n",
    "    \n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    #offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    offsets = product(range(0, nols, offset_x), range(0, nrows, offset_y))\n",
    "\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in offsets:\n",
    "        window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "def process_file(label, input_filepath, output_folder):\n",
    "    #OFFSET_X = 20\n",
    "    #OFFSET_Y = 20\n",
    "    with rio.open(input_filepath) as inds:\n",
    "        nodata = inds.nodata  # Get the NoData value from the dataset\n",
    "        meta = inds.meta.copy()\n",
    "        \n",
    "        for window, transform in get_tiles(inds):\n",
    "            if window.width == CHIP_SIZE and window.height == CHIP_SIZE:  # Check if the tile dimensions are as expected\n",
    "                data = inds.read(window=window)\n",
    "                if nodata is not None:\n",
    "                    valid_data_mask = (data != nodata)\n",
    "                else:\n",
    "                    valid_data_mask = (data == data)\n",
    "                \n",
    "                if valid_data_mask.any():  # Check if there's any valid data within the tile\n",
    "                    meta['transform'] = transform\n",
    "                    meta['width'], meta['height'] = window.width, window.height\n",
    "                    outpath = os.path.join(output_folder, output_filename.format(int(window.col_off), int(window.row_off)))\n",
    "                    with rio.open(outpath, 'w', **meta) as outds:\n",
    "                        outds.write(data)\n",
    "    print(f\"Processing for {label} completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for tile_number in TILENUMBER:\n",
    "        tif_path = f\"{THEFOLDER}\\\\PCLTILES\\\\pcltile_{tile_number}.tif\"\n",
    "        tif_dir = f\"{THEFOLDER}\\\\INFERENCETILES\\\\{tile_number}\"\n",
    "        os.makedirs(tif_dir, exist_ok=True)\n",
    "\n",
    "        resampled_files = [\n",
    "            process_dem(tif_path, tif_dir, tile_number),\n",
    "            process_lidar(tif_path, tif_dir, tile_number),\n",
    "            process_rivers(tif_path, tif_dir, tile_number),\n",
    "            process_roads(tif_path, tif_dir, tile_number)\n",
    "        ]\n",
    "\n",
    "        delete_non_resampled_files([os.path.basename(f) for f in resampled_files], tif_dir)\n",
    "\n",
    "        # Define input files as a dictionary\n",
    "        input_files = {\n",
    "            'lidar': f'output_resampled_dataLIDAR_{tile_number}.tif',\n",
    "            'dem': f'output_resampled_dataDEM_{tile_number}.tif',\n",
    "            'roads': f'output_resampled_dataRoads_{tile_number}.tif',\n",
    "            'rivers': f'output_resampled_dataRivers_{tile_number}.tif'\n",
    "        }\n",
    "        output_filename = 'tile_{}-{}.tif'\n",
    "\n",
    "        # Define the base output path\n",
    "        out_base_path = f\"{THEFOLDER}\\\\INFERENCETILES\"\n",
    "        os.makedirs(out_base_path, exist_ok=True)\n",
    "\n",
    "        # Process each file\n",
    "        for label, filename in input_files.items():\n",
    "            input_filepath = os.path.join(tif_dir, filename)\n",
    "            output_folder = os.path.join(out_base_path, label)\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            process_file(label, input_filepath, output_folder)\n",
    "\n",
    "        print(f\"Processing for tile {tile_number} completed.\")\n",
    "\n",
    "    print(\"All processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aabad222-7746-4152-9c46-e322bf2aa29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Define the directory path\n",
    "#directory_path = 'C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\PCLCONUS\\\\Input\\\\inferencetiles\\\\hag'\n",
    "\n",
    "# Regular expression to extract the identifier part of the filename 'tile_{identifier}.tif'\n",
    "pattern = re.compile(r'tile_(\\d+-\\d+)\\.tif')\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(output_folder)\n",
    "\n",
    "# Use a set to avoid duplicate identifiers\n",
    "identifiers = set()\n",
    "\n",
    "# Extract identifiers from filenames\n",
    "for file in files:\n",
    "    match = pattern.search(file)\n",
    "    if match:\n",
    "        identifiers.add(match.group(1))\n",
    "\n",
    "# Convert the set to a sorted list\n",
    "identifier_list = sorted(list(identifiers))\n",
    "print(len(identifier_list))\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88f6f862-25e2-4492-89f2-197b1a5a38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hag_max = 30.0\n",
    "# dem_max = 4379.1279296875\n",
    "# roads_max = 1.0\n",
    "# rivers_max = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5734bcb4-e31e-4cba-8c78-a7fd35b6881c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tilename = '0-0'\n",
    "# input_hag_path = f\"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\CNNPCLDEMO\\\\inferencetiles\\\\hag\\\\tile_{tilename}.tif\"\n",
    "# input_dem_path = f\"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\CNNPCLDEMO\\\\inferencetiles\\\\dem\\\\tile_{tilename}.tif\"\n",
    "# input_roads_path = f\"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\CNNPCLDEMO\\\\inferencetiles\\\\roads\\\\tile_{tilename}.tif\"\n",
    "# input_rivers_path = f\"C:\\\\Users\\\\smdur\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\CNNPCLDEMO\\\\inferencetiles\\\\rivers\\\\tile_{tilename}.tif\"\n",
    "\n",
    "def load_and_preprocess_image(hag_path, dem_path, roads_path, rivers_path):\n",
    "    with rasterio.open(hag_path) as src:\n",
    "        hag_image = src.read(1)\n",
    "    with rasterio.open(dem_path) as src:\n",
    "        dem_image = src.read(1)\n",
    "    with rasterio.open(roads_path) as src:\n",
    "        roads_image = src.read(1)\n",
    "    with rasterio.open(rivers_path) as src:\n",
    "        rivers_image = src.read(1)\n",
    "\n",
    "    # Normalize and stack the images\n",
    "    hag_image = np.array(hag_image).astype('float32') / hag_max\n",
    "    dem_image = np.array(dem_image).astype('float32') / dem_max\n",
    "    roads_image = np.array(roads_image).astype('float32') / roads_max\n",
    "    rivers_image = np.array(rivers_image).astype('float32') / rivers_max\n",
    "\n",
    "    # Stack images along the last dimension\n",
    "    combined_image = np.stack([hag_image, dem_image, roads_image, rivers_image], axis=-1)\n",
    "\n",
    "    # Add batch dimension\n",
    "    combined_image = np.expand_dims(combined_image, axis=0)\n",
    "    return combined_image\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(identifier_list)):\n",
    "    tilename = identifier_list[i]\n",
    "    #print(tilename)\n",
    "    #input_hag_path = f\"{out_base_path}\\\\lidar\\\\tile_{tilename}.tif\"\n",
    "    #input_dem_path = f\"{out_base_path}\\\\dem\\\\tile_{tilename}.tif\"\n",
    "    #input_roads_path = f\"{out_base_path}\\\\roads\\\\tile_{tilename}.tif\"\n",
    "    #input_rivers_path = f\"{out_base_path}\\\\tile_{tilename}.tif\"\n",
    "\n",
    "    input_hag_path = os.path.join(out_base_path, \"lidar\", f\"tile_{tilename}.tif\")\n",
    "    input_dem_path = os.path.join(out_base_path, \"dem\", f\"tile_{tilename}.tif\")\n",
    "    input_roads_path = os.path.join(out_base_path, \"roads\", f\"tile_{tilename}.tif\")\n",
    "    input_rivers_path = os.path.join(out_base_path, \"rivers\", f\"tile_{tilename}.tif\")\n",
    "\n",
    "\n",
    "    input_image = load_and_preprocess_image(input_hag_path, input_dem_path, input_roads_path, input_rivers_path)\n",
    "    predicted_image = model.predict(input_image)\n",
    "    predicted_image = np.squeeze(predicted_image)\n",
    "    \n",
    "    # Debug print to check if all outputs are the same\n",
    "    #print(\"Unique values in predicted output:\", np.unique(predicted_image))\n",
    "    \n",
    "    # Adjust the scaling factor based on how the labels were scaled during training\n",
    "    predicted_image *= 100\n",
    "    \n",
    "    #output_image_path = f\"{THEFOLDER}\\\\predictions\\\\predicted_tile_{tilename}.tif\"\n",
    "    predictions_folder = os.path.join(THEFOLDER, \"predictions\")\n",
    "    os.makedirs(predictions_folder, exist_ok=True)\n",
    "    output_image_path = os.path.join(predictions_folder, f\"predicted_tile_{tilename}.tif\")\n",
    "\n",
    "    \n",
    "    with rasterio.open(input_dem_path) as src: \n",
    "        profile = src.profile\n",
    "    \n",
    "    with rasterio.open(output_image_path, 'w', **profile) as dst:\n",
    "        dst.write(predicted_image.astype(rasterio.uint8), 1)\n",
    "\n",
    "print(\"Done\")\n",
    "# #Function to load and preprocess image pytorch\n",
    "# def load_and_preprocess_image(hag_path, dem_path, roads_path, rivers_path):\n",
    "#     with rasterio.open(hag_path) as src:\n",
    "#         hag_image = src.read(1)\n",
    "#     with rasterio.open(dem_path) as src:\n",
    "#         dem_image = src.read(1)\n",
    "#     with rasterio.open(roads_path) as src:\n",
    "#         roads_image = src.read(1)\n",
    "#     with rasterio.open(rivers_path) as src:\n",
    "#         rivers_image = src.read(1)\n",
    "\n",
    "#     # Normalize and stack the images\n",
    "#     hag_image = np.array(hag_image).astype('float32') / hag_max\n",
    "#     dem_image = np.array(dem_image).astype('float32') / dem_max\n",
    "#     roads_image = np.array(roads_image).astype('float32') / roads_max\n",
    "#     rivers_image = np.array(rivers_image).astype('float32') / rivers_max\n",
    "\n",
    "#     # Stack images along the last dimension\n",
    "#     combined_image = np.stack([hag_image, dem_image, roads_image, rivers_image], axis=-1)\n",
    "\n",
    "#     # Convert to PyTorch tensor and add batch dimension\n",
    "#     combined_image = torch.tensor(combined_image, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "#     return combined_image\n",
    "\n",
    "# for i in range(len(identifier_list)):\n",
    "#     tilename = identifier_list[i]\n",
    "\n",
    "#     input_hag_path = os.path.join(out_base_path, \"lidar\", f\"tile_{tilename}.tif\")\n",
    "#     input_dem_path = os.path.join(out_base_path, \"dem\", f\"tile_{tilename}.tif\")\n",
    "#     input_roads_path = os.path.join(out_base_path, \"roads\", f\"tile_{tilename}.tif\")\n",
    "#     input_rivers_path = os.path.join(out_base_path, \"rivers\", f\"tile_{tilename}.tif\")\n",
    "\n",
    "#     input_image = load_and_preprocess_image(input_hag_path, input_dem_path, input_roads_path, input_rivers_path)\n",
    "\n",
    "#     # Set the model to evaluation mode\n",
    "#     model.eval()\n",
    "    \n",
    "#     # Get the prediction from the model\n",
    "#     with torch.no_grad():\n",
    "#         predicted_image = model(input_image)\n",
    "    \n",
    "#     predicted_image = predicted_image.squeeze().cpu().numpy()\n",
    "    \n",
    "#     # Adjust the scaling factor based on how the labels were scaled during training\n",
    "#     predicted_image *= 100\n",
    "    \n",
    "#     predictions_folder = os.path.join(THEFOLDER, \"predictions\")\n",
    "#     os.makedirs(predictions_folder, exist_ok=True)\n",
    "#     output_image_path = os.path.join(predictions_folder, f\"predicted_tile_{tilename}.tif\")\n",
    "\n",
    "#     with rasterio.open(input_dem_path) as src: \n",
    "#         profile = src.profile\n",
    "    \n",
    "#     with rasterio.open(output_image_path, 'w', **profile) as dst:\n",
    "#         dst.write(predicted_image.astype(rasterio.uint8), 1)\n",
    "\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea2e91f-a316-4f81-ac3f-1bc58e1b2db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFF files merged successfully for chunk 1. Output: C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\mergedoutput\\predMerged_1.tif\n",
      "TIFF files merged successfully for chunk 2. Output: C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\mergedoutput\\predMerged_2.tif\n",
      "TIFF files merged successfully for chunk 3. Output: C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\mergedoutput\\predMerged_3.tif\n",
      "TIFF files merged successfully for chunk 4. Output: C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\mergedoutput\\predMerged_4.tif\n",
      "TIFF files merged successfully for chunk 5. Output: C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\mergedoutput\\predMerged_5.tif\n",
      "TIFF files merged successfully for chunk 6. Output: C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL23\\mergedoutput\\predMerged_6.tif\n",
      "Final TIFF files merged successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "TILENUMBER = ['70000-40000']\n",
    "\n",
    "# Define the base folder and output paths\n",
    "#THEFOLDER = r\"C:\\Users\\smdur\\OneDrive\\Desktop\\GlobalPCL\"\n",
    "predictions_folder = os.path.join(THEFOLDER, \"predictions\")\n",
    "output_dir = os.path.join(THEFOLDER, \"mergedoutput\")\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs(predictions_folder, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_base_name = \"predMerged_\"  # Base name for output files\n",
    "\n",
    "# Get a list of TIFF files\n",
    "tifs = glob.glob(os.path.join(predictions_folder, \"*.tif\"))\n",
    "\n",
    "# Define chunk size for processing\n",
    "chunk_size = 300\n",
    "\n",
    "# Calculate the number of chunks needed\n",
    "num_chunks = len(tifs) // chunk_size\n",
    "if len(tifs) % chunk_size != 0:\n",
    "    num_chunks += 1  # Add one more chunk for the remaining files\n",
    "\n",
    "# Loop through the TIFF files in chunks\n",
    "for chunk_id in range(num_chunks):\n",
    "    start_idx = chunk_id * chunk_size\n",
    "    end_idx = min((chunk_id + 1) * chunk_size, len(tifs))\n",
    "    chunk_tifs = tifs[start_idx:end_idx]\n",
    "    \n",
    "    output_tif = os.path.join(output_dir, f\"{output_base_name}{chunk_id + 1}.tif\")\n",
    "\n",
    "    merge_command_hag = [\n",
    "        \"python\",\n",
    "        \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "        \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "        \"-o\", output_tif,\n",
    "        \"-n\", \"-9999\",\n",
    "        \"-a_nodata\", \"-9999\",\n",
    "    ] + chunk_tifs\n",
    "\n",
    "    # Run the gdal_merge command for the current chunk\n",
    "    process_hag = subprocess.run(merge_command_hag, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "    # Check if the command for the current chunk was successful\n",
    "    if process_hag.returncode != 0:\n",
    "        # An error occurred, print the error\n",
    "        print(f\"Error occurred while merging TIFF files for chunk {chunk_id + 1}:\")\n",
    "        print(process_hag.stderr)\n",
    "    else:\n",
    "        print(f\"TIFF files merged successfully for chunk {chunk_id + 1}. Output: {output_tif}\")\n",
    "\n",
    "# Merge all chunks into a final output file\n",
    "final_output_tif = os.path.join(THEFOLDER, \"FINALOUTPUTTILES\", f\"predMerged_PCL_{TILENUMBER}.tif\")\n",
    "os.makedirs(os.path.dirname(final_output_tif), exist_ok=True)\n",
    "\n",
    "chunk_tifs = glob.glob(os.path.join(output_dir, \"*.tif\"))\n",
    "\n",
    "merge_command_final = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\smdur\\\\anaconda3\\\\envs\\\\globalpcl\\\\Scripts\\\\gdal_merge.py\",\n",
    "    \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "    \"-o\", final_output_tif,\n",
    "    \"-n\", \"-9999\",\n",
    "    \"-a_nodata\", \"-9999\",\n",
    "] + chunk_tifs\n",
    "\n",
    "# Run the gdal_merge command for the final merge\n",
    "process_final = subprocess.run(merge_command_final, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Check if the command for the final merge was successful\n",
    "if process_final.returncode != 0:\n",
    "    # An error occurred, print the error\n",
    "    print(\"Error occurred while merging final TIFF files:\")\n",
    "    print(process_final.stderr)\n",
    "else:\n",
    "    print(\"Final TIFF files merged successfully.\")\n",
    "\n",
    "# # Clean up temporary chunk files\n",
    "# for tif in chunk_tifs:\n",
    "#     try:\n",
    "#         os.remove(tif)\n",
    "#         print(f\"Deleted {tif}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to delete {tif}: {e}\")\n",
    "\n",
    "# print(\"Done\")\n",
    "\n",
    "# import shutil\n",
    "\n",
    "# if os.path.exists(predictions_folder):\n",
    "#     shutil.rmtree(predictions_folder)\n",
    "# os.makedirs(predictions_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa074bc7-4ce1-4967-a31e-ab6fffc8dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
