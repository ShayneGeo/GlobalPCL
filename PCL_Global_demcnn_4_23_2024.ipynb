{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4eb61-1443-4e02-b1bf-9581a69d25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for Fort Collins, CO\n",
    "min_lon = -105.115\n",
    "max_lon = -105.032\n",
    "min_lat = 40.521\n",
    "max_lat = 40.610\n",
    "\n",
    "# Define the bounding box\n",
    "bbox_of_interest = [min_lon, min_lat, max_lon, max_lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1980b-2182-403d-9e74-9ed010633e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f371485d-8ada-45b2-8b84-1cae16a886d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=[\"cop-dem-glo-30\"],\n",
    "    bbox=bbox_of_interest\n",
    ")\n",
    "items = list(search.get_items())\n",
    "print(f\"Returned {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f24f1b-47f8-4fca-a319-e69900654e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n",
    "data = (\n",
    "    rioxarray.open_rasterio(signed_asset.href)\n",
    "    .squeeze()\n",
    "    .drop(\"band\")\n",
    "    #.coarsen({\"y\": 5, \"x\": 5})\n",
    "    #.mean()\n",
    ")\n",
    "\n",
    "data.rio.write_crs(\"EPSG:4326\", inplace=True)  # Change \"EPSG:4326\" to the appropriate CRS if different\n",
    "\n",
    "# Specify the path where you want to save the TIFF file\n",
    "output_tif_path = \"C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTIF\\\\output_dataDEM.tif\"\n",
    "\n",
    "# Save the data as a GeoTIFF file\n",
    "data.rio.to_raster(output_tif_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26689dfe-0093-499b-8537-b08e3a6fb372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this ensures all tiles are widthtile by heighttile\n",
    "import os\n",
    "from itertools import product\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "\n",
    "in_path = 'C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTIF\\\\'\n",
    "input_filename = 'output_dataDEM.tif'\n",
    "out_path = 'C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTILES3\\\\'\n",
    "output_filename = 'tile_{}-{}.tif'\n",
    "widthtile = 300\n",
    "heighttile = 300\n",
    "\n",
    "def get_tiles(ds, width=widthtile, height=heighttile):\n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    #offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    offsets = product(range(0, nols, 10), range(0, nrows, 10))\n",
    "\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in offsets:\n",
    "        window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "with rio.open(os.path.join(in_path, input_filename)) as inds:\n",
    "    tile_width, tile_height = widthtile, heighttile\n",
    "    nodata = inds.nodata  # Get the NoData value from the dataset\n",
    "    meta = inds.meta.copy()\n",
    "\n",
    "    for window, transform in get_tiles(inds):\n",
    "        if window.width == tile_width and window.height == tile_height:  # Check if the tile dimensions are as expected\n",
    "            data = inds.read(window=window)\n",
    "            if nodata is not None:\n",
    "                # Modified check for NoData to include tolerance for floating-point rasters\n",
    "                valid_data_mask = (data != nodata)\n",
    "            else:\n",
    "                # If NoData value is not set, consider all data as valid\n",
    "                valid_data_mask = (data == data)\n",
    "\n",
    "            if valid_data_mask.any():  # Check if there's any valid data within the tile\n",
    "                meta['transform'] = transform\n",
    "                meta['width'], meta['height'] = window.width, window.height\n",
    "                outpath = os.path.join(out_path, output_filename.format(int(window.col_off), int(window.row_off)))\n",
    "                with rio.open(outpath, 'w', **meta) as outds:\n",
    "                    outds.write(data)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27dce6-da55-47ec-86c6-0ae71b662594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "import numpy as np\n",
    "\n",
    "# Path to the directory containing your TIFF tiles\n",
    "tiles_directory = 'C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTILES3\\\\'\n",
    "\n",
    "# Path to the TIFF file containing the PCL data\n",
    "pcl_tif_path = 'C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\Input\\\\pcl_west_wgs_CO.tif'\n",
    "\n",
    "# Lists to store image data and labels (assuming all tiles are the same size and have the same number of bands)\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Count number of files to preallocate arrays\n",
    "num_files = len([name for name in os.listdir(tiles_directory) if name.endswith('.tif')])\n",
    "first_file = True\n",
    "\n",
    "\n",
    "# Open the PCL data TIFF file\n",
    "with rasterio.open(pcl_tif_path) as pcl_src:\n",
    "    pcl_data = pcl_src.read(1)  # Read the first band\n",
    "\n",
    "    # Loop through each tile in the directory\n",
    "    for filename in os.listdir(tiles_directory):\n",
    "\n",
    "        if filename.endswith(\".tif\"):\n",
    "            filepath = os.path.join(tiles_directory, filename)\n",
    "            with rasterio.open(filepath) as src:\n",
    "                data = src.read()  # Read all bands of the tile\n",
    "                if first_file:\n",
    "                    # Initialize the numpy arrays with correct dimensions\n",
    "                    images = np.zeros((num_files, *data.shape), dtype=data.dtype)\n",
    "                    labels = np.zeros(num_files, dtype=np.float32)\n",
    "                    idx = 0\n",
    "                    first_file = False\n",
    "                images[idx] = data\n",
    "                # Calculate the geographic coordinates of the center pixel of the tile\n",
    "                center_x, center_y = (src.width // 2, src.height // 2)\n",
    "                lon, lat = src.xy(center_y, center_x)  # Get lon and lat of the center pixel\n",
    "\n",
    "                # Convert geographic coordinates to row and col in the PCL TIFF\n",
    "                pcl_row, pcl_col = rowcol(pcl_src.transform, lon, lat)\n",
    "\n",
    "                # Extract the PCL value at this position\n",
    "                center_pcl_value = pcl_data[pcl_row, pcl_col]\n",
    "                labels[idx] = center_pcl_value  # Append the PCL value as label\n",
    "                idx += 1\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of the images array:\", images.shape)\n",
    "print(\"Shape of the labels array:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d2141-0ef4-40a2-bcdb-3a5367e5c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Reshape images to fit the model input\n",
    "images = images.reshape(len(labels), 300, 300, 1)  # Reshape for CNN input\n",
    "\n",
    "# Create the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='linear')  # Assuming a regression output\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(images, labels, epochs=1, batch_size=64, validation_split=0.2)\n",
    "\n",
    "## optional \n",
    "# Save the model to a HDF5 file\n",
    "#model.save('C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\SavedModels\\\\model_300by300.h5')\n",
    "\n",
    "# # Later or in another script after re-importing the necessary libraries\n",
    "# # Load the model back from the file\n",
    "# loaded_model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# # Check the architecture of the loaded model\n",
    "# loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd622eb5-4fa7-4b2a-b75f-cbc3866c8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict labels using the trained model\n",
    "predicted_labels = model.predict(images).flatten()  # Flatten to make it 1D, matching labels' shape\n",
    "\n",
    "# Scatter plot of Actual vs. Predicted labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(labels, predicted_labels, alpha=0.5)\n",
    "plt.title('Actual vs. Predicted PCL Values')\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.grid(True)\n",
    "plt.plot([labels.min(), labels.max()], [labels.min(), labels.max()], 'k--')  # Line for perfect predictions\n",
    "plt.show()\n",
    "\n",
    "# Optionally, display the error metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(labels, predicted_labels)\n",
    "r2 = r2_score(labels, predicted_labels)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R^2 Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa3bfa-9e94-4827-b5b9-8b28bd40939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "import rasterio as rio\n",
    "from rasterio import windows\n",
    "\n",
    "in_path = 'C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTIF\\\\'\n",
    "input_filename = 'output_dataDEM.tif'\n",
    "out_path = 'C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTILESInference\\\\'\n",
    "output_filename = 'tile_{}-{}.tif'\n",
    "widthtile = 500\n",
    "heighttile = 500\n",
    "\n",
    "def get_tiles(ds, width=widthtile, height=heighttile):\n",
    "    nols, nrows = ds.meta['width'], ds.meta['height']\n",
    "    #offsets = product(range(0, nols, width), range(0, nrows, height))\n",
    "    offsets = product(range(0, nols, 10), range(0, nrows, 10))\n",
    "    big_window = windows.Window(col_off=0, row_off=0, width=nols, height=nrows)\n",
    "    for col_off, row_off in offsets:\n",
    "        window = windows.Window(col_off=col_off, row_off=row_off, width=width, height=height).intersection(big_window)\n",
    "        transform = windows.transform(window, ds.transform)\n",
    "        yield window, transform\n",
    "\n",
    "with rio.open(os.path.join(in_path, input_filename)) as inds:\n",
    "    tile_width, tile_height = widthtile, heighttile\n",
    "    nodata = inds.nodata  # Get the NoData value from the dataset\n",
    "    meta = inds.meta.copy()\n",
    "\n",
    "    for window, transform in get_tiles(inds):\n",
    "        data = inds.read(window=window)\n",
    "        if nodata is not None:\n",
    "            # Modified check for NoData to include tolerance for floating-point rasters\n",
    "            valid_data_mask = (data != nodata)\n",
    "        else:\n",
    "            # If NoData value is not set, consider all data as valid\n",
    "            valid_data_mask = (data == data)\n",
    "\n",
    "        if valid_data_mask.any():  # Check if there's any valid data within the tile\n",
    "            meta['transform'] = transform\n",
    "            meta['width'], meta['height'] = window.width, window.height\n",
    "            outpath = os.path.join(out_path, output_filename.format(int(window.col_off), int(window.row_off)))\n",
    "            with rio.open(outpath, 'w', **meta) as outds:\n",
    "                outds.write(data)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1765e-f647-45ff-8b37-637b5e5e5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches_overlap(image, transform, patch_size=300, overlap=299):\n",
    "    \"\"\"Extracts overlapping patches from the image along with their center coordinates.\"\"\"\n",
    "    half_patch = patch_size // 2\n",
    "    stride = patch_size - overlap\n",
    "    patches = []\n",
    "    coords = []\n",
    "    for i in range(0, image.shape[0] - patch_size + 1, stride):\n",
    "        for j in range(0, image.shape[1] - patch_size + 1, stride):\n",
    "            patch = image[i:i + patch_size, j:j + patch_size]\n",
    "            if patch.shape[0] == patch_size and patch.shape[1] == patch_size:\n",
    "                patches.append(patch)\n",
    "                # Get the geographic coordinates for the center of the patch\n",
    "                x, y = transform * (j + half_patch, i + half_patch)\n",
    "                coords.append((x, y))\n",
    "    return np.array(patches), coords\n",
    "\n",
    "with rasterio.open('C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\DEMTILESInference\\\\tile_0-10.tif') as src:\n",
    "    large_image = src.read(1)  # Read the first band\n",
    "    transform = src.transform  # Spatial transform for coordinate conversion\n",
    "\n",
    "image_patches, patch_coords = extract_patches_overlap(large_image, transform)\n",
    "\n",
    "image_patches = image_patches.reshape(-1, 300, 300, 1)  # Add channel dimension\n",
    "predictions = model.predict(image_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b99ca9-c55b-4a95-950d-01c536fcdb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "\n",
    "# Create a GeoDataFrame from these coordinates\n",
    "gdf = gpd.GeoDataFrame({\n",
    "    'geometry': [Point(x, y) for x, y in patch_coords]\n",
    "}, crs=\"EPSG:4326\")  # Make sure to set the correct coordinate reference system\n",
    "\n",
    "# Extract x and y coordinates\n",
    "gdf[\"x\"] = gdf.geometry.x\n",
    "gdf[\"y\"] = gdf.geometry.y\n",
    "gdf['prediction'] = predictions  \n",
    "# Now you have gdf with x, y columns along with geometry\n",
    "print(gdf.head())\n",
    "\n",
    "import xarray as xr\n",
    "da = (\n",
    "    gdf.set_index([\"y\", \"x\"])\n",
    "    .prediction\n",
    "    .to_xarray()\n",
    ")\n",
    "da.rio.to_raster(\"C:\\\\Users\\\\OneDrive\\\\Desktop\\\\GLOBALPCL\\\\OutputTIF\\\\output_file0_10_300w300h.tif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
